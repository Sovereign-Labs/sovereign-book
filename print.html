<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Sovereign SDK Book</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="/assets/sovereign-dark-highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="1-intro.html"><strong aria-hidden="true">1.</strong> Intro</a></li><li class="chapter-item expanded "><a href="2-getting-started.html"><strong aria-hidden="true">2.</strong> Getting Started</a></li><li class="chapter-item expanded "><a href="3-0-intro.html"><strong aria-hidden="true">3.</strong> Writing Your Application</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="3-1-implementing-a-module.html"><strong aria-hidden="true">3.1.</strong> Implementing a Module</a></li><li class="chapter-item expanded "><a href="3-2-testing-your-module.html"><strong aria-hidden="true">3.2.</strong> Testing Your Module</a></li><li class="chapter-item expanded "><a href="3-3-adding-your-module.html"><strong aria-hidden="true">3.3.</strong> Adding Your Module to Your Runtime</a></li><li class="chapter-item expanded "><a href="3-4-signing-and-submitting-txs.html"><strong aria-hidden="true">3.4.</strong> Wallets and Accounts</a></li><li class="chapter-item expanded "><a href="3-5-advanced.html"><strong aria-hidden="true">3.5.</strong> Advanced Topics</a></li><li class="chapter-item expanded "><a href="3-6-performance.html"><strong aria-hidden="true">3.6.</strong> Performance</a></li><li class="chapter-item expanded "><a href="3-7-prebuilt-modules.html"><strong aria-hidden="true">3.7.</strong> Prebuilt Modules</a></li></ol></li><li class="chapter-item expanded "><a href="4-0-intro.html"><strong aria-hidden="true">4.</strong> Instrumenting Your Rollup</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="4-1-metrics.html"><strong aria-hidden="true">4.1.</strong> Metrics</a></li><li class="chapter-item expanded "><a href="4-2-logging.html"><strong aria-hidden="true">4.2.</strong> Logging</a></li></ol></li><li class="chapter-item expanded "><a href="5-sdk-advanced-features.html"><strong aria-hidden="true">5.</strong> SDK Advanced Features</a></li><li class="chapter-item expanded "><a href="6-0-intro.html"><strong aria-hidden="true">6.</strong> SDK Contributors</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="6-1-transaction-lifecycle.html"><strong aria-hidden="true">6.1.</strong> Transaction Lifecyle</a></li><li class="chapter-item expanded "><a href="6-2-abstractions.html"><strong aria-hidden="true">6.2.</strong> Main Abstractions</a></li><li class="chapter-item expanded "><a href="6-3-forced-sequencer-registration.html"><strong aria-hidden="true">6.3.</strong> Forced Sequencer Registration</a></li><li class="chapter-item expanded "><a href="6-4-gas.html"><strong aria-hidden="true">6.4.</strong> Gas</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="sovereign-dark">Sovereign Dark</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Sovereign SDK Book</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-sovereign-sdk-book"><a class="header" href="#the-sovereign-sdk-book">The Sovereign SDK Book</a></h1>
<p>Welcome to the Sovereign SDK Book, your comprehensive guide to the industry's most flexible toolkit for building high-performance, real-time rollups.</p>
<p>We built this SDK to give developers, from solo builders to large teams, the power to create onchain applications that were previously impossible.</p>
<p>With transaction confirmations under 2-5 milliseconds, the Sovereign SDK is fast enough to bring complex financial systems, like Central-Limit Orderbooks (CLOBs), fully on-chain.</p>
<p>And most importantly, after months of extensive load-testing, it's production-ready. Let's build the next Hyperliquid.</p>
<img src="https://github.com/Sovereign-Labs/sovereign-sdk/blob/nightly/assets/banner.jpg?raw=true" style="border-radius: 10px">
<h2 id="why-build-a-dedicated-rollup-for-your-application"><a class="header" href="#why-build-a-dedicated-rollup-for-your-application">Why Build a Dedicated Rollup For Your Application?</a></h2>
<p>For almost a decade, developers have been forced to build applications on shared, general-purpose blockchains. This model forces apps with vastly different needs to compete for the same limited blockspace. Building your application as a dedicated rollup gives you three strategic advantages:</p>
<ol>
<li><strong>Dedicated Throughput:</strong> Your users will never have to compete with a viral NFT drop. A rollup gives your application its own dedicated lane, ensuring a consistently fast and affordable user experience.</li>
<li><strong>Capturing More Value:</strong> On shared blockchains, user fees primarily benefit the chain operators (i.e. L1 validators or general-purpose L2 sequencer). With a rollup, your application and its users can capture the vast majority of that value, creating a sustainable economic engine for your project.</li>
<li><strong>Full Control &amp; Flexibility:</strong> Go beyond the limitations of a shared virtual machine. A rollup gives you full control over the execution environment, allowing you to define your own rules for how transactions are processed. <strong>With a rollup, you're in the driver's seat.</strong></li>
</ol>
<h2 id="why-choose-the-sovereign-sdk"><a class="header" href="#why-choose-the-sovereign-sdk">Why Choose the Sovereign SDK?</a></h2>
<p>The Sovereign SDK is designed around four key principles to provide an unmatched developer and user experience:</p>
<ul>
<li><strong>Total Customization:</strong> While rollups promise flexibility, existing frameworks are overly restrictive. Sovereign SDK delivers on that promise with its modular Rust runtime, empowering you to customize as much or as little as needed. Easily add custom fee logic, integrate tailored authenticators, prioritize specific transaction types, or even swap out the authenticated state store—all without wrestling with legacy code.</li>
<li><strong>Best-in-Class Performance:</strong> With 2-5ms soft confirmations and throughput exceeding 10,000 TPS, the Sovereign SDK is orders of magnitude faster than competing frameworks like Orbit, the OP Stack, or the Cosmos SDK.</li>
<li><strong>A Developer-Friendly Experience:</strong> Write your logic in standard Rust, run <code>cargo build</code>, and get a complete full-node implementation with REST &amp; WebSocket APIs, an indexer, auto-generated OpenAPI specs, and a sequencer  with automatic failover out of the box. No boilerplate or deep blockchain expertise required.</li>
<li><strong>Future-Proof Architecture:</strong> Never get locked into yesterday's tech stack. With the Sovereign SDK, you can switch data availability layers or zkVMs with just a few lines of code, ensuring your project remains agile for years to come.</li>
</ul>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How It Works</a></h2>
<p>As a developer, you write your rollup's business logic in Rust, and the SDK handles the complexity of creating a complete, production-ready node implementation.</p>
<p>The magic happens in two stages: <strong>real-time execution</strong> and <strong>on-chain settlement</strong>.</p>
<ol>
<li>
<p><strong>Real-Time Execution (Soft Confirmations):</strong> Users send transactions to a <strong>sequencer</strong>. The sequencer executes these transactions instantly (typically in under 2-5ms) and returns a "soft confirmation" back to the user. This provides a real-time user experience that feels like a traditional web application.</p>
</li>
<li>
<p><strong>On-Chain Settlement &amp; Verification:</strong> Periodically, the sequencer batches thousands of these transactions and posts them to an underlying <strong>Data Availability (DA) layer</strong> like Celestia. From this point, the rest of the network—the full nodes—can read the ordered data and execute the transactions to independently verify the new state of the rollup.</p>
</li>
</ol>
<p>Finally, specialized actors called <strong>provers</strong> (in zk-rollup mode) or <strong>attesters</strong> (in optimistic-rollup mode) generate cryptographic proofs  or attestations that the state was computed correctly. These are posted back to the DA layer, allowing light clients and bridges to securely verify the rollup's state without having to re-execute every transaction.</p>
<p>This two-stage process gives you the best of both worlds: the instant, centralized execution needed for high-performance applications, combined with the censorship-resistance and trust-minimized verification of a traditional blockchain.</p>
<h2 id="ready-to-build"><a class="header" href="#ready-to-build">Ready to Build?</a></h2>
<p>Now that you understand the power and flexibility of the Sovereign SDK, you're ready to get your hands dirty. In the next chapter, "Getting Started," we'll walk you through cloning a starter repository and running your first rollup in minutes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>This guide provides a starting point for building rollups with the Sovereign SDK.</p>
<p>It includes everything you need to create a rollup with customizable modules, REST API for state queries, TypeScript SDK for submitting transactions, WebSocket endpoints to subscribe to transactions and events, built-in token management, and much more.</p>
<h2 id="prerequisites"><a class="header" href="#prerequisites">Prerequisites</a></h2>
<p>Before you begin, ensure you have the following installed:</p>
<ul>
<li><strong>Rust</strong>: 1.88.0 or later
<ul>
<li>Install via <a href="https://rustup.rs/">rustup</a>: <code>curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh</code></li>
<li>The project will automatically install the correct version via <code>rust-toolchain.toml</code></li>
</ul>
</li>
<li><strong>Node.js</strong>: 18.0 or later (for Typescript client)
<ul>
<li>Install via <a href="https://nodejs.org/en/download">official website</a></li>
</ul>
</li>
<li><strong>Git</strong>: For cloning the repository</li>
</ul>
<h2 id="running-with-mock-da"><a class="header" href="#running-with-mock-da">Running with Mock DA</a></h2>
<h3 id="1-clone-the-starter-repository-and-navigate-to-the-rollup-directory"><a class="header" href="#1-clone-the-starter-repository-and-navigate-to-the-rollup-directory">1. Clone the starter repository and navigate to the rollup directory:</a></h3>
<pre><code class="language-bash">git clone https://github.com/Sovereign-Labs/sov-rollup-starter.git
cd sov-rollup-starter/crates/rollup/
</code></pre>
<h3 id="2-optional-clean-the-database-for-a-fresh-start"><a class="header" href="#2-optional-clean-the-database-for-a-fresh-start">2. (Optional) Clean the database for a fresh start:</a></h3>
<pre><code class="language-bash">make clean-db
</code></pre>
<h3 id="3-start-the-rollup-node"><a class="header" href="#3-start-the-rollup-node">3. Start the rollup node:</a></h3>
<pre><code class="language-bash">cargo run --bin node
</code></pre>
<h3 id="explore-the-rest-api-endpoints-via-swagger-ui"><a class="header" href="#explore-the-rest-api-endpoints-via-swagger-ui">Explore the REST API endpoints via Swagger UI</a></h3>
<p>The rollup starter includes several built-in modules: Bank (for token management), Paymaster, Hyperlane, and more. You can query any state item in these modules:</p>
<pre><code class="language-bash">open http://localhost:12346/swagger-ui/#/ 
</code></pre>
<h3 id="example-query-the-example-modules-state-value"><a class="header" href="#example-query-the-example-modules-state-value">Example: Query the Example Module's state value:</a></h3>
<pre><code class="language-bash">curl -X 'GET' \
  'http://0.0.0.0:12346/modules/example-module/state/value' \
  -H 'accept: application/json'
</code></pre>
<p>For now, you should just see null returned for the value state item, as the item hasn't been initialized:</p>
<pre><code class="language-bash">{"data":{"value":null},"meta":{}}
</code></pre>
<h2 id="programmatic-interaction-with-typescript"><a class="header" href="#programmatic-interaction-with-typescript">Programmatic Interaction with Typescript</a></h2>
<h3 id="set-up-the-typescript-client"><a class="header" href="#set-up-the-typescript-client">Set up the Typescript client:</a></h3>
<pre><code class="language-bash">cd ../../js # Navigate back up to the right directory
npm install 
</code></pre>
<h3 id="the-typescript-script-demonstrates-the-complete-transaction-flow"><a class="header" href="#the-typescript-script-demonstrates-the-complete-transaction-flow">The Typescript script demonstrates the complete transaction flow:</a></h3>
<pre><code class="language-js">// 1. Initialize rollup client
const rollup = await createStandardRollup({ // defaults to http://localhost:12346, or pass url: "&lt;custom-endpoint&gt;"
  context: {
    defaultTxDetails: {
      max_priority_fee_bips: 0,
      max_fee: "100000000",
      gas_limit: null,
      chain_id: 4321, // Must match chain_id in constants.toml
    },
  },
});

// 2. Initialize signer
const privKey = "0d87c12ea7c12024b3f70a26d735874608f17c8bce2b48e6fe87389310191264";
let signer = new Secp256k1Signer(privKey, chainHash);

// 3. Create a transaction (call message)
let createTokenCall: RuntimeCall = {
  bank: {
    create_token: {
      admins: [],
      token_decimals: 8,
      supply_cap: 100000000000,
      token_name: "Example Token",
      initial_balance: 1000000000,
      mint_to_address: signerAddress, // derived from privKey above (can be any valid address)
    },
  },
};

// 4. Send transaction
let tx_response = await rollup.call(createTokenCall, { signer });
</code></pre>
<h3 id="run-the-script"><a class="header" href="#run-the-script">Run the script:</a></h3>
<pre><code class="language-bash">npm run start 
</code></pre>
<p>You should see a transaction soft-confirmation with events:</p>
<pre><code class="language-bash">Tx sent successfully. Response:
{
  data: {
    id: '0xbfe14371219807b236c5c719ea85be63174fe0c673e8b229e4913e6f6273a5a0',
    events: [
      {
        type: 'event',
        number: 0,
        key: 'Bank/TokenCreated',
        value: {
          token_created: {
            token_name: 'Example Token',
            coins: {
              amount: '1000000000',
              token_id: 'token_10jrdwqkd0d4zf775np8x3tx29rk7j5m0nz9wj8t7czshylwhnsyqpgqtr9'
            },
            mint_to_address: { user: '0x9b08ce57a93751ae790698a2c9ebc76a78f23e25' },
            minter: { user: '0x9b08ce57a93751ae790698a2c9ebc76a78f23e25' },
            supply_cap: '100000000000',
            admins: []
          }
        },
        module: { type: 'moduleRef', name: 'Bank' },
        tx_hash: '0xbfe14371219807b236c5c719ea85be63174fe0c673e8b229e4913e6f6273a5a0'
      }
    ],
    receipt: { result: 'successful', data: { gas_used: [ 21119, 21119 ] } },
    status: 'submitted'
  },
  meta: {}
}
</code></pre>
<h3 id="subscribe-to-events-from-the-sequencer"><a class="header" href="#subscribe-to-events-from-the-sequencer">Subscribe to events from the sequencer:</a></h3>
<p>You can also subscribe to events from the sequencer (you need to uncomment the subscription code blocks <a href="js/src/index.ts#L53">in the script</a>):</p>
<pre><code class="language-js">// Subscribe to events
async function handleNewEvent(event: any): Promise&lt;void&gt; {
  console.log(event);
}
const subscription = rollup.subscribe("events", handleNewEvent);

// Unsubscribe
subscription.unsubscribe();
</code></pre>
<h3 id="interacting-with-different-modules"><a class="header" href="#interacting-with-different-modules">Interacting with different modules</a></h3>
<p>To interact with different modules, simply change the call message. The top-level key corresponds to the <a href="/crates/stf/src/runtime.rs#L85">module's variable name in the runtime</a>, and the nested key is the <a href="fix-link">CallMessage</a> enum variant in snake_case:</p>
<pre><code class="language-js">// Example: Call the ExampleModule's SetValue method
let setValueCall: RuntimeCall = {
  example_module: {  // Must match Runtime field name of the module
    set_value: 10  
  },
};
</code></pre>
<p>This transaction would set the ExampleModule's state value to 10. Try setting the <a href="js/src/index.ts#L39">example file's call message</a> to the expression above and re-running the script. Then verify that the ExampleModule's value changed using <a href="2-getting-started.html#example-query-the-example-modules-state-value">the curl command</a> we showed earlier.</p>
<p>This time, the curl command should return:</p>
<pre><code class="language-bash">{"data":{"value":10},"meta":{}}
</code></pre>
<h2 id="whats-next"><a class="header" href="#whats-next">What's Next?</a></h2>
<p>You've now successfully launched a rollup, queried its state, and submitted a transaction. You've seen how the <code>bank</code> and <code>example_module</code> are just two components of a larger system.</p>
<p>To truly make this rollup your own, you'll want to build custom logic. In the next chapter, "Writing Your Application," we'll dive deep into the heart of the Sovereign SDK and teach you how to implement your very own module from scratch.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="writing-your-application"><a class="header" href="#writing-your-application">Writing Your Application</a></h1>
<p>At its core, a rollup is a specialized blockchain that processes transactions from a data availability (DA) layer. The logic that determines how your rollup behaves is defined by two key components: the <strong>runtime</strong> and its <strong>modules</strong>.</p>
<p>The runtime is the orchestrator of your rollup. It receives serialized transactions from the DA layer, deserializes them, and routes them to the appropriate modules for execution. Think of it as the central nervous system that connects all your application logic together. The runtime defines which modules your rollup supports, how they interact with each other, and how the rollup's state is initialized at genesis.</p>
<p>Modules, on the other hand, contain the actual business logic of your application. Each module manages its own state and defines the operations (called "call messages") that users can perform. For example, you might have a token module for handling transfers, a governance module for voting, or a custom trading module for your specific use case. When a user wants to interact with your rollup, they send a call message targeting a specific module, and the runtime ensures it gets delivered and executed atomically.</p>
<p>The starter package already includes several production-ready modules like Bank (for token management), Sequencer Registry, Accounts, and Hyperlane (for cross-chain messaging). It also provides an Example Module that serves as a template you can modify.</p>
<h3 id="lets-begin"><a class="header" href="#lets-begin">Let's Begin</a></h3>
<p>With this context in mind, we're ready to start building. This chapter will guide you through the complete journey of application development on the Sovereign SDK, from creating your first module to enabling user interactions and exploring advanced features.</p>
<p>Here is the path we'll take:</p>
<ol>
<li><a href="3-1-implementing-a-module.html"><strong>Implementing a Module:</strong></a> First, we'll define your module's state and business logic—the heart of your application.</li>
<li><a href="3-2-testing-your-module.html"><strong>Testing Your Module:</strong></a> We'll then write robust tests to ensure your logic is correct and secure.</li>
<li><a href="3-3-integrating-your-module.html"><strong>Integrating Your Module:</strong></a> Next, you'll learn how to add your finished module into a live rollup runtime.</li>
<li><a href="3-4-signing-and-submitting-txs.html"><strong>Wallets and Accounts:</strong></a> With your module integrated, we'll explore how users can create accounts and sign transactions to interact with it.</li>
<li><a href="3-5-advanced.html"><strong>Advanced Topics:</strong></a> From there, we'll dive into powerful features like hooks and custom APIs to extend your module's capabilities.</li>
<li><a href="3-6-performance.html"><strong>Performance:</strong></a> You'll learn how to optimize your module for maximum throughput and efficiency.</li>
<li><a href="3-7-prebuilt-modules.html"><strong>Prebuilt Modules:</strong></a> Finally, we'll review the rich ecosystem of existing modules you can leverage to accelerate your development.</li>
</ol>
<p>Let's dive in!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="implementing-a-module"><a class="header" href="#implementing-a-module">Implementing a Module</a></h1>
<p>A module is the basic unit of functionality in the Sovereign SDK. It's a self-contained piece of onchain logic that manages its own state and defines how users can interact with it.</p>
<p>The best way to learn how modules work is to build one. In this section, we'll create a simple but complete <code>ValueSetter</code> module from scratch. This module will allow a designated admin address to set a <code>u32</code> value in the rollup's state. After the walkthrough, we'll dive deeper into each of the concepts introduced.</p>
<p>Think of this tutorial as your guide to the fundamental components of a module. Once you understand the concepts, we recommend starting your own module by copying the <a href="fix-link"><code>ExampleModule</code></a> provided in the starter repository. It has all the necessary dependencies and file structure pre-configured for you.</p>
<h2 id="a-step-by-step-walkthrough-the-valuesetter-module"><a class="header" href="#a-step-by-step-walkthrough-the-valuesetter-module">A Step-by-Step Walkthrough: The <code>ValueSetter</code> Module</a></h2>
<h3 id="1-defining-the-module-struct"><a class="header" href="#1-defining-the-module-struct">1. Defining the Module Struct</a></h3>
<p>First, we define the module's structure and the state it will manage. This struct tells the SDK what data to store onchain.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sov_modules_api::{Module, ModuleId, ModuleInfo, StateValue, Spec};

// This is the struct that will represent our module.
// It must derive `ModuleInfo` to be a valid module.
#[derive(ModuleInfo)]
pub struct ValueSetter&lt;S: Spec&gt; {
    /// The `#[id]` attribute is required and uniquely identifies the module instance.
    #[id]
    pub id: ModuleId,

    /// The `#[state]` attribute marks a field as a state variable.
    /// `StateValue` stores a single, typed value.
    #[state]
    pub value: StateValue&lt;u32&gt;,

    /// We'll also store the address of the admin who is allowed to change the value.
    /// S:Address is the address type of our rollup. More on `Spec` later.
    #[state]
    pub admin: StateValue&lt;S::Address&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-defining-types-for-the-module-trait"><a class="header" href="#2-defining-types-for-the-module-trait">2. Defining Types for the <code>Module</code> Trait</a></h3>
<p>Next, we define the associated types required by the <code>Module</code> trait: its configuration, its callable methods, and its events.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Continuing in the same file...
use sov_modules_api::{Context, macros::UniversalWallet};
use serde::{Serialize, Deserialize};
use borsh::{BorshSerialize, BorshDeserialize};

// The configuration for our module at genesis. This will be deserialized from `genesis.json`.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
pub struct ValueSetterConfig&lt;S: Spec&gt; {
    pub initial_value: u32,
    pub admin: S::Address,
}

// The actions a user can take. Our module only supports one action: setting the value.
// This `CallMessage` enum defines the module's public API.
// Deriving these traits ensures it's portable and compatible with wallets and block explorers.
#[derive(
    BorshDeserialize,
    BorshSerialize,
    Serialize,
    Deserialize,
    schemars::JsonSchema,
    UniversalWallet,
    Clone,
    Debug,
    PartialEq,
)]
#[serde(rename_all = "snake_case")]
pub enum CallMessage {
    SetValue(u32),
}

// The event our module will emit after a successful action.
#[derive(BorshDeserialize, BorshSerialize, Serialize, Deserialize, Debug, PartialEq)]
#[serde(rename_all = "snake_case")]
pub enum Event {
    ValueChanged(u32),
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-implementing-the-module-trait-logic"><a class="header" href="#3-implementing-the-module-trait-logic">3. Implementing the <code>Module</code> Trait Logic</a></h3>
<p>With our types defined, we can now implement the <code>Module</code> trait itself.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::Result;
use sov_modules_api::{GenesisState, TxState, EventEmitter, Error};

// Now, we implement the `Module` trait.
impl&lt;S: Spec&gt; Module for ValueSetter&lt;S&gt; {
    type Spec = S;
    type Config = ValueSetterConfig&lt;S&gt;;
    type CallMessage = CallMessage;
    type Event = Event;

    // `genesis` is called once when the rollup is deployed to initialize the state.
    fn genesis(&amp;mut self, _header: &amp;&lt;S::Da as sov_modules_api::DaSpec&gt;::BlockHeader, config: &amp;Self::Config, state: &amp;mut impl GenesisState&lt;S&gt;) -&gt; Result&lt;(), Error&gt; {
        self.value.set(&amp;config.initial_value, state)
            .map_err(Into::&lt;anyhow::Error&gt;::into)?;
        self.admin.set(&amp;config.admin, state)
            .map_err(Into::&lt;anyhow::Error&gt;::into)?;
        Ok(())
    }

    // `call` is called when a user submits a transaction to the module.
    fn call(&amp;mut self, msg: Self::CallMessage, context: &amp;Context&lt;S&gt;, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;(), Error&gt; {
        match msg {
            CallMessage::SetValue(new_value) =&gt; {
                self.set_value(new_value, context, state)
                    .map_err(Into::&lt;anyhow::Error&gt;::into)?;

                Ok(())
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-writing-the-business-logic"><a class="header" href="#4-writing-the-business-logic">4. Writing the Business Logic</a></h3>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>The final piece is to write the private set_value method containing our business logic.

impl&lt;S: Spec&gt; ValueSetter&lt;S&gt; {
    fn set_value(&amp;mut self, new_value: u32, context: &amp;Context&lt;S&gt;, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;()&gt; {
        let admin = self.admin.get_or_err(state)??;

        if &amp;admin != context.sender() {
            return Err(anyhow::anyhow!("Only the admin can set the value.").into());
        }

        self.value.set(&amp;new_value, state)?;
        self.emit_event(state, Event::ValueChanged(new_value));
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<p>With that, you've implemented a complete module! Now, let's break down the concepts we used in more detail.</p>
<hr />
<h2 id="anatomy-of-a-module-a-deeper-look"><a class="header" href="#anatomy-of-a-module-a-deeper-look">Anatomy of a Module: A Deeper Look</a></h2>
<h3 id="derived-traits-moduleinfo-and-modulerestapi"><a class="header" href="#derived-traits-moduleinfo-and-modulerestapi">Derived Traits: <code>ModuleInfo</code> and <code>ModuleRestApi</code></a></h3>
<p>You should always derive <code>ModuleInfo</code> on your module, since it does important
work like laying out your state values in the database. If you forget to derive
this trait, the SDK will throw a helpful error.</p>
<p>The <code>ModuleRestApi</code> trait is optional but highly recommended. It automatically generates RESTful API endpoints for the <code>#[state]</code> items in your module. Each item's endpoint will have the name <code>{hostname}/modules/{module-name}/{field-name}/</code>, with all items automatically converted to <code>kebab-casing</code>. For example, for the <code>value</code> field in our <code>ValueSetter</code> walkthrough, the SDK would generate an endpoint at the path <code>/modules/value-setter/value</code>.</p>
<p>Note that <code>ModuleRestApi</code> can't always generate endpoints for you. If it can't figure out how to generate an endpoint for a particular state value, it will simply skip it by default. If you want to override this behavior and throw a compiler error if endpoint generation fails, you can add the <code>#[rest_api(include)]</code> attribute.</p>
<h3 id="the-spec-generic"><a class="header" href="#the-spec-generic">The <code>Spec</code> Generic</a></h3>
<p>Modules are generic over a <code>Spec</code> type, which provides access to core rollup types. By being generic over the <code>Spec</code>, you ensure that you can easily change things like the <code>Address</code> format used by your module later on without rewriting your logic.</p>
<p>Key types provided by <code>Spec</code> include:</p>
<ul>
<li><code>S::Address</code>: The address format used on the rollup.</li>
<li><code>S::Da::Address</code>: The address format of the underlying Data Availability layer.</li>
<li><code>S::Da::BlockHeader</code>: The block header type of the DA layer.</li>
</ul>
<h3 id="state-module-and-id-fields"><a class="header" href="#state-module-and-id-fields"><code>#[state]</code>, <code>#[module]</code>, and <code>#[id]</code> fields</a></h3>
<ul>
<li><strong><code>#[id]</code></strong>: Every module must have exactly one <code>#[id]</code> field. The <code>ModuleInfo</code> macro uses this to store the module's unique, auto-generated identifier.</li>
<li><strong><code>#[module]</code></strong>:  This attribute declares a dependency on another module. For example, if our <code>ValueSetter</code> needed to pay a fee, we could add <code>#[module] pub bank: sov_bank::Bank&lt;S&gt;</code>, allowing us to call <code>self.bank.transfer(...)</code> in our logic.</li>
<li><strong><code>#[state]</code></strong>: This attribute marks a field as a state variable that will be stored in the database.</li>
</ul>
<h3 id="state-types-in-depth"><a class="header" href="#state-types-in-depth">State Types In-Depth</a></h3>
<p>The SDK provides several state types, each for a different use case:</p>
<ul>
<li><strong><code>StateValue&lt;T&gt;</code></strong>: Stores a single item of type T. We used this for <code>value</code> and <code>admin</code> variables.</li>
<li><strong><code>StateMap&lt;K, V&gt;</code></strong>: Stores a key-value mapping.</li>
<li><strong><code>StateVec&lt;T&gt;</code></strong>: Stores an ordered list of items, accessible by index.</li>
</ul>
<p>The generic types can be any deterministic Rust data structure, anything from a simple <code>u32</code> to a complex <code>BTreeMap</code>.</p>
<p><strong>Accessory State</strong>: For each state type, there is a corresponding <code>AccessoryState*</code> variant (e.g., <code>AccessoryStateMap</code>). Accessory state is special: it can be read and written via the API, but it is <strong>write-only</strong> during a transaction. This makes it much cheaper to use for data that doesn't affect onchain logic, like indexing purchase histories for an off-chain frontend.</p>
<p><strong>Codecs</strong>: By default, all state is serialized using Borsh. If you need to store a type from a third-party library that only supports serde, you can specify a different codec: StateValue&lt;ThirdPartyType, BcsCodec&gt;.</p>
<h3 id="the-module-trait-and-its-methods"><a class="header" href="#the-module-trait-and-its-methods">The <code>Module</code> Trait and its Methods</a></h3>
<p>The <code>Module</code> trait is the core of your application's onchain logic. The implementation you wrote in the walkthrough satisfies this trait's requirements.</p>
<p>Let's look at a simplified version of the trait definition to understand its components:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Module {
    /// The configuration needed to initialize the module, deserialized from `genesis.json`.
    type Config;

    /// A module-defined enum representing the actions a user can take.
    type CallMessage: Debug + BorshSerialize + BorshDeserialize + Clone;

    /// A module-defined enum representing the events emitted by successful calls.
    type Event: Debug + BorshSerialize + BorshDeserialize + 'static + core::marker::Send;

    /// `genesis` is called once when the rollup is deployed to initialize state.
    ///
    /// The logic here must be deterministic, but since it only runs once,
    /// efficiency is not a primary concern.
    fn genesis(
        &amp;mut self,
        genesis_rollup_header: &amp;&lt;&lt;Self::Spec as Spec&gt;::Da as DaSpec&gt;::BlockHeader,
        config: &amp;Self::Config,
        state: &amp;mut impl GenesisState&lt;Self::Spec&gt;,
    ) -&gt; Result&lt;(), Error&gt;;


    /// `call` accepts a `CallMessage` and executes it, changing the module's state.
    fn call(
        &amp;mut self,
        message: Self::CallMessage,
        context: &amp;Context&lt;Self::Spec&gt;,
        state: &amp;mut impl TxState&lt;Self::Spec&gt;,
    ) -&gt; Result&lt;CallResponse, Error&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h4 id="genesis"><a class="header" href="#genesis"><code>genesis</code></a></h4>
<p>The <code>genesis</code> function is called once when the rollup is deployed. It uses the module's <code>Config</code> struct (defined as the associated <code>type Config</code>) to initialize the state. This <code>Config</code> is deserialized from the <code>genesis.json</code> file.</p>
<h4 id="call"><a class="header" href="#call"><code>call</code></a></h4>
<p>The <code>call</code> function provides the transaction processing logic. It accepts a structured <code>CallMessage</code> from a user and a <code>Context</code> containing metadata like the sender's address. If your <code>call</code> function returns an error, the SDK automatically reverts all state changes and discards any events, ensuring that transactions are atomic.</p>
<p>You can define the <code>CallMessage</code> to be any type you wish, but an enum is usually best. Be sure to derive <code>borsh</code> and <code>serde</code> serialization, as well as <code>schemars::JsonSchema</code> and <code>UniversalWallet</code>. This ensures your <code>CallMessage</code> is portable across different languages and frontends.</p>
<p><strong>A Note on Gas and Security</strong>: Just like Ethereum smart contracts, modules accept inputs that are pre-validated by the chain. Your call method does not need to worry about authenticating the transaction sender. The SDK also automatically meters gas for state accesses. You only need to manually charge gas (using <a href="fix-link"><code>Module::charge_gas(...)</code></a>) if your module performs heavy computation outside of state reads/writes.</p>
<h3 id="events"><a class="header" href="#events">Events</a></h3>
<p>Events are the primary way your module communicates with the outside world. They are structured data included in transaction receipts and are essential for:</p>
<ul>
<li>Querying via REST API.</li>
<li>Streaming in real-time via WebSockets.</li>
<li>Building off-chain indexers and databases.</li>
</ul>
<p><strong>Important</strong>: Events are only emitted when transactions succeed. If a transaction reverts, all its events are discarded. This makes events perfect for reliably indexing onchain state.</p>
<h3 id="error-handling"><a class="header" href="#error-handling">Error Handling</a></h3>
<p>Modules use <code>anyhow::Result</code> for error handling, providing rich context that helps both developers and users understand what went wrong.</p>
<p>When your call method returns an Err, the SDK automatically reverts all state changes made during the transaction. This ensures that your module's logic is atomic.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::{Context, Result};

fn transfer(&amp;self, from: &amp;S::Address, amount: u64, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;()&gt; {
    let balance = self.balances.get(from, state)?
        .with_context(|| format!("Failed to read balance for sender {}", from))?
        .unwrap_or(0);
    
    if balance &lt; amount {
        return Err(anyhow::anyhow!("Insufficient balance: {} &lt; {}", balance, amount));
    }
    // ...
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p>For more details on error handling patterns, see the <a href="3-5-advanced.html#error-handling">Advanced Topics</a> section.</p>
<h3 id="next-step-ensuring-correctness"><a class="header" href="#next-step-ensuring-correctness">Next Step: Ensuring Correctness</a></h3>
<p>You now have a deep understanding of how to define, implement, and structure a module. With this foundation, you're ready to test your module.</p>
<p>In the next section, <strong>"Testing Your Module,"</strong> we'll show you how to use the SDK's powerful testing framework to write comprehensive tests for your new module.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="testing-your-module"><a class="header" href="#testing-your-module">Testing Your Module</a></h1>
<p>Testing is crucial for building reliable modules. The SDK provides a comprehensive testing framework that makes it easy to write thorough tests for your modules.</p>
<h2 id="test-infrastructure-overview"><a class="header" href="#test-infrastructure-overview">Test Infrastructure Overview</a></h2>
<p>There are several key components for testing:</p>
<ul>
<li><strong>TestRunner</strong>: A stateful test harness that manages your runtime environment</li>
<li><strong>TestUser</strong>: Test accounts with preconfigured balances</li>
<li><strong>TransactionTestCase</strong>: A structured way to define test scenarios with assertions</li>
<li><strong>Runtime Generation Macros</strong>: Automatically include all core modules</li>
</ul>
<h2 id="setting-up-your-test-environment"><a class="header" href="#setting-up-your-test-environment">Setting Up Your Test Environment</a></h2>
<h3 id="1-create-your-test-runtime"><a class="header" href="#1-create-your-test-runtime">1. Create Your Test Runtime</a></h3>
<p>The <code>generate_optimistic_runtime!</code> macro automatically includes all core modules (Bank, Accounts, SequencerRegistry, etc.), so you only need to add your custom modules:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sov_test_utils::runtime::optimistic::generate_optimistic_runtime;

// Your module's crate
use your_module::YourModule;

// Generate a runtime with core modules + your custom module
generate_optimistic_runtime!(
    TestRuntime &lt;=  // Your test runtime name
    your_module: YourModule&lt;S&gt; // Your custom module
);
<span class="boring">}</span></code></pre></pre>
<h3 id="2-define-your-genesis-configuration"><a class="header" href="#2-define-your-genesis-configuration">2. Define Your Genesis Configuration</a></h3>
<p>Set up the initial state with test users:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sov_test_utils::{HighLevelOptimisticGenesisConfig, TestRunner, TestUser};

pub struct TestData&lt;S: Spec&gt; {
    pub admin: TestUser&lt;S&gt;,
    pub user1: TestUser&lt;S&gt;,
    pub user2: TestUser&lt;S&gt;,
}

pub fn setup() -&gt; (TestData&lt;TestSpec&gt;, TestRunner&lt;TestRuntime, TestSpec&gt;) {
    let genesis_config = HighLevelOptimisticGenesisConfig::generate()
        .add_accounts_with_default_balance(3);
    
    let mut users = genesis_config.additional_accounts().to_vec();
    let test_data = TestData {
        user2: users.pop().unwrap(),
        user1: users.pop().unwrap(),
        admin: users.pop().unwrap(),
    };
    
    let runner = TestRunner::new_with_genesis(/* ... */);
    
    (test_data, runner)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="writing-your-first-test"><a class="header" href="#writing-your-first-test">Writing Your First Test</a></h2>
<p>Here's a complete example testing a simple module operation:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(test)]
mod tests {
    use super::*;
    use sov_test_utils::{TestRunner, TransactionTestCase};
    
    #[test]
    fn test_module_operation() {
        // Setup runner and get test user 
        let (test_data, mut runner) = setup();
        let user = &amp;test_data.user1;
        
        // Execute a transaction
        runner.execute_transaction(TransactionTestCase {
            input: user.create_plain_message::&lt;TestRuntime, YourModule&gt;(
                CallMessage::SetValue { value: 42 }
            ),
            assert: Box::new(|result, state| {
                // Verify the transaction succeeded
                assert!(result.tx_receipt.is_successful());
                
                // Query and verify state
                let current_value = YourModule::default()
                    .get_value(state)
                    .unwrap_infallible()  // State access can't fail in tests
                    .unwrap();            // Handle the Option
                assert_eq!(current_value, 42);
            }),
        });
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="running-your-tests"><a class="header" href="#running-your-tests">Running Your Tests</a></h2>
<p>Execute your tests from your module's root directory using standard Rust commands:</p>
<pre><code class="language-bash"># Navigate to your module directory 
cd your-module/

# Run all tests in your module
cargo test

# Run specific test
cargo test test_module_operation

# Run with output for debugging
cargo test -- --nocapture
</code></pre>
<h2 id="testing-patterns"><a class="header" href="#testing-patterns">Testing Patterns</a></h2>
<h3 id="1-error-scenario-testing"><a class="header" href="#1-error-scenario-testing">1. Error Scenario Testing</a></h3>
<p>Test that your module handles errors correctly:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_insufficient_balance() {
    let (test_data, mut runner) = setup();
    let sender = &amp;test_data.user1;
    let receiver = &amp;test_data.user2;
    
    runner.execute_transaction(TransactionTestCase {
        input: sender.create_plain_message::&lt;TestRuntime, Bank&gt;(
            CallMessage::Transfer {
                to: receiver.address(),
                coins: Coins { 
                    amount: 999_999_999_999, // More than the sender has 
                    token_id: config_gas_token_id() 
                },
            }
        ),
        assert: Box::new(|result, _state| {
            // Verify the transaction reverted
            assert!(result.tx_receipt.is_reverted());
            
            // Check the specific error message
            if let TxEffect::Reverted(contents) = &amp;result.tx_receipt.tx_effect {
                assert!(contents.reason.to_string().contains("Insufficient balance"));
            }
        }),
    });
}
<span class="boring">}</span></code></pre></pre>
<h3 id="2-event-testing"><a class="header" href="#2-event-testing">2. Event Testing</a></h3>
<p>Verify that your module emits the correct events. Note that the event enum name (e.g., <code>TestRuntimeEvent</code>) is automatically generated based on your runtime name.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_event_emission() {
    let (test_data, mut runner) = setup();
    let user = &amp;test_data.user1;
    
    runner.execute_transaction(TransactionTestCase {
        input: user.create_plain_message::&lt;TestRuntime, YourModule&gt;(
            CallMessage::CreateItem { name: "Test".into() }
        ),
        assert: Box::new(move |result, _state| {
            assert!(result.tx_receipt.is_successful());
            assert_eq!(result.events.len(), 1);
            
            assert_eq!(
                result.events[0],
                TestRuntimeEvent::YourModule(your_module::Event::ItemCreated {
                    creator: user.address(),
                    name: "Test".into()
                })
            );
        }),
    });
}
<span class="boring">}</span></code></pre></pre>
<h3 id="3-time-based-testing"><a class="header" href="#3-time-based-testing">3. Time-Based Testing</a></h3>
<p>Test operations that depend on blockchain progression by advancing slots:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_time_delayed_operation() {
    let (users, mut runner) = setup();

    // 1. Initiate a time-locked operation (e.g., a vesting schedule)

    // 2. Advance blockchain time
    runner.advance_slots(100); // Advance 100 slots

    // 3. Now, the second part of the operation should succeed
    runner.execute_transaction(/* ... complete the operation ... */);
}
<span class="boring">}</span></code></pre></pre>
<h3 id="4-standalone-state-queries"><a class="header" href="#4-standalone-state-queries">4. Standalone State Queries</a></h3>
<p>While you can query state within a transaction's assert block, you can also query the latest visible state at any point using <code>runner.query_visible_state</code>. This is useful for verifying the initial genesis state or checking state after non-transaction events like advancing slots. This can be useful if you especially have custom <a href="3-5-advanced.html#hooks"><code>hooks</code></a>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[test]
fn test_state_queries() {
    let (test_data, mut runner) = setup();
    let admin = &amp;test_data.admin;

    // Query the initial genesis state before any transactions
    runner.query_visible_state(|state| {
        // Query a value from your module
        let item_count = YourModule::&lt;S&gt;::default()
            .get_item_count(state)
            .unwrap_infallible()
            .unwrap();
        assert_eq!(item_count, 0);

    });

    // 2. Execute a transaction that changes state
    runner.execute_transaction(TransactionTestCase {
        input: admin.create_plain_message::&lt;TestRuntime, YourModule&gt;(
            CallMessage::CreateItem { name: "Test".into() }
        ),
        assert: |result, _| assert!(result.tx_receipt.is_successful()),
    });

    // Query again to see the new state
    runner.query_visible_state(|state| {
        let item_count = YourModule::&lt;S&gt;::default()
            .get_item_count(state)
            .unwrap_infallible()
            .unwrap();
        assert_eq!(item_count, 1);
    });
}
<span class="boring">}</span></code></pre></pre>
<h3 id="5-custom-module-genesis-configuration"><a class="header" href="#5-custom-module-genesis-configuration">5. Custom Module Genesis Configuration</a></h3>
<p>If your module requires initialization parameters in genesis (like an admin address or initial values), you'll need to provide a custom configuration:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use sov_test_utils::{GenesisConfig};

fn setup_with_config() -&gt; (TestUser&lt;TestSpec&gt;, TestRunner&lt;TestRuntime, TestSpec&gt;) {
    let genesis_config = HighLevelOptimisticGenesisConfig::generate()
        .add_accounts_with_default_balance(1);
    
    // Get the admin user
    let admin = genesis_config
        .additional_accounts()
        .first()
        .unwrap()
        .clone();
    
    // Create genesis with your module's configuration
    let genesis = GenesisConfig::from_minimal_config(
        genesis_config.into(),
        YourModuleConfig {
            admin: admin.address(),
            initial_value: 1000,
            // Other module-specific parameters
        },
    );
    
    let runner = TestRunner::new_with_genesis(
        genesis.into_genesis_params(),
        TestRuntime::default()
    );
    
    (admin, runner)
}
<span class="boring">}</span></code></pre></pre>
<h2 id="additional-resources"><a class="header" href="#additional-resources">Additional Resources</a></h2>
<p>For more advanced testing scenarios, the <a href="fix-link-https://docs.rs/sov-test-utils"><code>sov-test-utils</code> crate</a> is your primary resource. It contains all the testing components covered in this guide and much more.</p>
<p>We highly recommend exploring the documentation for the <strong><a href="fix-link-https://docs.rs/sov-test-utils/latest/sov_test_utils/runtime/struct.TestRunner.html"><code>TestRunner</code></a></strong> struct, which provides methods for more complex scenarios, including:</p>
<ul>
<li>Executing and asserting on batches of transactions.</li>
<li>Querying historical state at specific block heights.</li>
<li>Customizing gas and fee configurations.</li>
<li>Running an integrated REST API server for off-chain testing.</li>
</ul>
<p>The <code>sov-test-utils</code> crate provides a comprehensive toolkit for testing every aspect of your module's behavior.</p>
<h3 id="ready-for-primetime"><a class="header" href="#ready-for-primetime">Ready for Primetime</a></h3>
<p>With a thoroughly tested module, you can be confident in your logic's correctness and robustness. It's now time to bring your module to life by integrating it into a live rollup runtime.</p>
<p>In the next section, "Integrating Your Module," we'll guide you through adding your module to the Runtime struct, configuring its genesis state, and making it a live component of your application.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="adding-your-module-to-your-runtime"><a class="header" href="#adding-your-module-to-your-runtime">Adding Your Module to Your Runtime</a></h1>
<p>Once you've built and tested your module, the final step is to integrate it into your rollup runtime. This section will walk you through the process of adding your module to a new rollup project based on our rollup starter template.</p>
<h2 id="step-1-add-your-module-as-a-dependency"><a class="header" href="#step-1-add-your-module-as-a-dependency">Step 1: Add Your Module as a Dependency</a></h2>
<p>First, add your module to the workspace dependencies in the root <code>Cargo.toml</code>:</p>
<pre><code class="language-toml">[workspace.dependencies]
# ... existing dependencies ...

# Add your module here
your-module = { path = "../path/to/your-module" }
# Or if published:
# your-module = { version = "0.1.0" }
# Or if the module is available on Github:
# your-module = { git = "https://github.com/your-github/your-module", rev = "dfd0624c32f5fb363c2190e9d911605663f7d693" }
</code></pre>
<p>Then add it to your STF crate's dependencies in <code>crates/stf/Cargo.toml</code> (where your <code>Runtime</code> is typically located in):</p>
<pre><code class="language-toml">[dependencies]
# ... existing dependencies ...

your-module = { workspace = true }

[features]
default = []
native = [
    # ... existing native features ...
    "your-module/native",
]
</code></pre>
<h2 id="step-2-add-your-module-to-the-runtime-struct"><a class="header" href="#step-2-add-your-module-to-the-runtime-struct">Step 2: Add Your Module to the Runtime Struct</a></h2>
<p>The central piece of your rollup's logic is the <a href="fix-link"><code>Runtime</code> struct</a>, usually found in <code>crates/stf/src/runtime.rs</code>. This struct lists all the modules that compose your rollup. To integrate your module, simply add it as a new field to this struct.</p>
<p>The Runtime struct uses several derive macros (<code>#[derive(Genesis, DispatchCall, ...)]</code>) that automatically generate the boilerplate code for state initialization, transaction dispatching, and message encoding.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use your_module::YourModule;

#[derive(Genesis, Hooks, DispatchCall, Event, MessageCodec, RuntimeRestApi)]
pub struct Runtime&lt;S: Spec&gt; {
    /// The bank module is responsible for managing tokens
    pub bank: sov_bank::Bank&lt;S&gt;,
    
    /// The accounts module manages user accounts and addresses
    pub accounts: sov_accounts::Accounts&lt;S&gt;,
    
    // ... other modules ...
    
    /// Your custom module
    pub your_module: YourModule&lt;S&gt;,
}
<span class="boring">}</span></code></pre></pre>
<h2 id="step-3-configure-genesis-state"><a class="header" href="#step-3-configure-genesis-state">Step 3: Configure Genesis State</a></h2>
<p>When your rollup is first launched, it populates its initial state from a <code>genesis.json</code> file. You need to tell the rollup how to initialize your module by adding a corresponding entry to this file.</p>
<h3 id="understanding-genesisjson"><a class="header" href="#understanding-genesisjson">Understanding <code>genesis.json</code></a></h3>
<p>The <code>genesis.json</code> is a simple key-value store where each key is the snake-case name of a module in your <code>Runtime</code> struct, and the value is the initial configuration for that module.</p>
<p>When the rollup starts, it deserializes this JSON into your module's <code>Config</code> struct (which you define in your module) and passes it to your module's <code>genesis()</code> method.</p>
<p>You will find this file in the root of your rollup project: <code>your-rollup/{DA_LAYER_NAME}/genesis.json</code>.</p>
<h3 id="adding-your-modules-configuration"><a class="header" href="#adding-your-modules-configuration">Adding Your Module's Configuration</a></h3>
<p>There are two cases:</p>
<p><strong>1. Your Module Requires No Initial Configuration:</strong></p>
<p>If your module's <code>Config</code> is an empty struct (e.g., <code>pub struct MyModuleConfig {}</code>) or can be created with <code>Default::default()</code>, you just need to add its name to <code>genesis.json</code> with an empty JSON object <code>{}</code>.</p>
<pre><code class="language-json">// In your-rollup/genesis.json
{
  "bank": { ... },
  "sequencer_registry": { ... },
  "accounts": { ... },
  "my_awesome_module": {}
}
</code></pre>
<p><strong>2. Your Module Requires Initial Configuration:</strong></p>
<p>If your module needs initial parameters (like an admin address or an initial value), you must provide them in the JSON object. The JSON fields must exactly match the fields of your module's <code>Config</code> struct.</p>
<p>For example, if your module has this <code>Config</code> struct:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// In modules/my-awesome-module/src/lib.rs
#[derive(serde::Deserialize, serde::Serialize)]
pub struct MyAwesomeModuleConfig {
    pub admin_address: S::Address,
    pub initial_counter: u64,
}
<span class="boring">}</span></code></pre></pre>
<p>Your <code>genesis.json</code> entry would look like this:</p>
<pre><code class="language-json">// In your-rollup/genesis.json
{
  // ... other modules
  "my_awesome_module": {
    "admin_address": "0x633dD354F65261d7a64E10459508F8713a537149",
    "initial_counter": 100
  }
}
</code></pre>
<h2 id="step-4-configure-rollup-constant"><a class="header" href="#step-4-configure-rollup-constant">Step 4: Configure Rollup Constant</a></h2>
<p>The <code>constants.toml</code> file in your rollup's root directory allows you to configure chain-level parameters that don't change often. You should update this file to reflect your rollup's identity.</p>
<pre><code class="language-toml"># Change these to make your chain unique
CHAIN_ID = 12345  # Your unique chain ID
CHAIN_NAME = "my-awesome-rollup"

# Gas configuration
GAS_TOKEN_NAME = "GAS"

# Other compile time parameters...
</code></pre>
<p>These values are compiled into your rollup binary.</p>
<h2 id="step-5-build-and-run"><a class="header" href="#step-5-build-and-run">Step 5: Build and Run</a></h2>
<p>With everything configured, you can run your rollup with your module:</p>
<pre><code class="language-bash"># Run the node
cargo run --bin node
</code></pre>
<p>Your rollup is now operational! You can:</p>
<ul>
<li>Send transactions to your module</li>
<li>Query its state via the REST API</li>
<li>See events in transaction receipts</li>
</ul>
<h2 id="troubleshooting"><a class="header" href="#troubleshooting">Troubleshooting</a></h2>
<h3 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h3>
<p><strong>Module not found in genesis</strong></p>
<ul>
<li>Ensure the module name in <code>genesis.json</code> matches the field name in your Runtime struct</li>
</ul>
<p><strong>Serialization errors</strong></p>
<ul>
<li>Verify your genesis configuration matches your module's <code>Config</code> type</li>
<li>Check that all addresses use the correct format (0x-prefixed hex)</li>
</ul>
<p><strong>Build errors</strong></p>
<ul>
<li>Ensure all feature flags are properly configured</li>
<li>Check that your module exports all required types</li>
</ul>
<h3 id="your-module-is-live"><a class="header" href="#your-module-is-live">Your Module is Live!</a></h3>
<p>Congratulations! Your module is now a fully integrated part of a running rollup. You have successfully navigated the complete development lifecycle, from implementation and testing to deployment on your local machine.</p>
<p>You've built the core logic, but now the crucial question is: how do users actually interact with it? How do they create accounts, manage keys, and sign transactions to call your new module's methods?</p>
<p>The next section, "Wallets and Accounts," will bridge this gap. We'll explore how to leverage the SDK's Ethereum-compatible account system and use client-side tooling to sign and submit transactions to your rollup, bringing your application to life for end-users.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="wallets-and-accounts"><a class="header" href="#wallets-and-accounts">Wallets and Accounts</a></h2>
<p>Now that you've built, tested, and integrated your module, the final step is enabling users to interact with it. This section covers how accounts, wallets, and transaction signing work in the Sovereign SDK.</p>
<p>The core design principle is <strong>Ethereum compatibility</strong>. Sovereign SDK rollups use standard Ethereum addresses and signatures (Secp256k1), which unlocks the vast Ethereum tooling ecosystem. However, there are important nuances to understand.</p>
<h4 id="the-sovereign-sdk-transaction-type"><a class="header" href="#the-sovereign-sdk-transaction-type">The Sovereign SDK Transaction Type</a></h4>
<p>A critical distinction to grasp is that while addresses and signatures are Ethereum-compatible, the <strong>transaction format itself is unique to your rollup</strong>. A Sovereign SDK rollup does not natively accept a raw, RLP-encoded Ethereum transaction.</p>
<p>Instead, your rollup's <code>Runtime</code> defines a custom <code>RuntimeCall</code> enum, which represents all possible actions a user can take. When a user sends a transaction, they are essentially sending a serialized <code>RuntimeCall</code> message that has been signed with their Ethereum-compatible key.</p>
<h4 id="signing-transactions-today-the-web3js-sdk--privy"><a class="header" href="#signing-transactions-today-the-web3js-sdk--privy">Signing Transactions Today: The <code>web3.js</code> SDK &amp; Privy</a></h4>
<p>The primary way for users and developers to sign and submit these custom transactions today is through the Sovereign <code>web3.js</code> client library. This library provides two main signer implementations:</p>
<p><strong>1. <code>Secp256k1Signer</code> (For Developers)</strong></p>
<p>This is a straightforward signer for programmatic use, where you have direct access to a raw private key. It's perfect for scripting, backend services, or testing.</p>
<pre><code class="language-ts">import { Secp256k1Signer } from "@sovereign-labs/signers";

// Initialize with a raw private key
const privKey = "0d87c12ea7c12024b3f70a26d735874608f17c8bce2b48e6fe87389310191264";
const signer = new Secp256k1Signer(privKey);

// Use the signer to send a transaction
await rollup.call(myCallMessage, { signer });
</code></pre>
<p><strong>2. <code>PrivySigner</code> (For User-Facing Applications)</strong></p>
<p>For most applications, asking users for a private key is not feasible or secure. This is where <strong>Privy</strong> comes in. Privy is a powerful wallet-as-a-service provider that allows users to create a non-custodial wallet using familiar Web2 logins like email or social accounts. They can also connect their existing wallets (like MetaMask or Phantom).</p>
<p>The <code>sov-rollup-starter</code> repository includes a <a href="fix-link">full example of integrating the <code>PrivySigner</code></a>, making it the most realistic and user-friendly way to onboard users to your rollup today. It handles all the complexity of wallet creation and signing, allowing users to interact with your application seamlessly.</p>
<h4 id="the-future-supporting-all-ethereum-wallets-by-leveraging-eip-712"><a class="header" href="#the-future-supporting-all-ethereum-wallets-by-leveraging-eip-712">The Future: Supporting All Ethereum Wallets by Leveraging EIP-712</a></h4>
<p>While Privy provides an excellent experience, it is crucial to meet users where they're at and enable support for all existing Ethereum wallets (including hardware wallets). This will be enabled by implementing a new <strong>EIP-712 Authenticator</strong> for the Sovereign SDK runtime (which we hope to complete by August 24, 2025).</p>
<p><strong>EIP-712</strong> is an Ethereum standard for signing typed, structured data. Instead of asking the user to sign a cryptic hash, EIP-712 allows wallets to display the transaction data in a human-readable, key-value format. This dramatically improves security and user experience, as users can see exactly what they are approving.</p>
<p>For example, a signature request using EIP-712 would look like this in MetaMask:</p>
<p><img src="/assets/message-signing.png" alt="A message signing request from Hyperliquid" /></p>
<p>This upcoming feature, inspired by the pioneering work of Hyperliquid, will allow developers to support all Ethereum wallets.</p>
<h3 id="next-steps-advanced-features"><a class="header" href="#next-steps-advanced-features">Next Steps: Advanced Features</a></h3>
<p>You now have a complete picture of how to build a module and enable users to interact with it. From here, you can dive into the "Advanced Topics" to learn about hooks, custom APIs, and other powerful features that will allow you to build truly sophisticated onchain applications.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-topics"><a class="header" href="#advanced-topics">Advanced Topics</a></h1>
<p>This section covers advanced module development features that go beyond basic functionality. While the core module implementation handles state management and transaction processing, you may need these additional capabilities for production use cases.</p>
<p>All features in this section are optional. Start with the basic module implementation and add these capabilities as your requirements grow.</p>
<h2 id="hooks"><a class="header" href="#hooks">Hooks</a></h2>
<p>In addition to <code>call</code>, modules may <em>optionally</em> implement <code>Hooks</code>. Hooks can run at
the begining and end of every rollup block and every transaction. <code>BlockHooks</code>
are great for taking actions that need to happen before or after any
transaction executes in a block - but be careful, no one pays for the
computation done by <code>BlockHooks</code>, so doing any heavy computation can make your
rollup vulnerable to DOS attacks.</p>
<p><code>TxHooks</code> are useful for checking invariants, or to allow your module to monitor actions
being taken by other modules. Unlike <code>BlockHooks</code>, <code>TxHooks</code> are paid for by the
user who sent each transaction.</p>
<p>The <code>FinalizeHook</code> is great for doing indexing. It can only modify
<code>AccessoryState</code>, which makes it cheap to run but means that the results will
only be visible via the API.</p>
<p>Using the hooks is somewhat unusual - most applications only need to modify
their state in response to user actions - but it's a powerful tool in some
cases. See the documentation on
<a href="fix-link/crates/module-system/sov-modules-api/src/hooks.rs#L76"><code>BlockHooks</code></a>
and
<a href="fix-link/crates/module-system/sov-modules-api/src/hooks.rs#L12"><code>TxHooks</code></a>
and
<a href="fix-link/crates/module-system/sov-modules-api/src/hooks.rs#L120"><code>FinalizeHook</code></a>
more details.</p>
<h2 id="error-handling-1"><a class="header" href="#error-handling-1">Error Handling</a></h2>
<h3 id="when-to-panic-vs-return-errors"><a class="header" href="#when-to-panic-vs-return-errors">When to Panic vs Return Errors</a></h3>
<p><strong>Panic when:</strong></p>
<ul>
<li>You encounter a bug that indicates broken invariants</li>
<li>The error is unrecoverable and continuing would compromise state integrity</li>
</ul>
<p>When you panic, the rollup will shut down. This is correct for bugs that could corrupt your state.</p>
<p><strong>Return errors when:</strong></p>
<ul>
<li>User input is invalid</li>
<li>Business logic conditions aren't met (insufficient balance, unauthorized access, etc.)</li>
<li>Any expected failure condition</li>
</ul>
<p>Transaction errors automatically revert all state changes.</p>
<h3 id="writing-error-messages"><a class="header" href="#writing-error-messages">Writing Error Messages</a></h3>
<p>Your error messages serve both end users and developers. Use <code>anyhow</code> with context to provide meaningful errors:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use anyhow::{Context, Result};

fn transfer(&amp;self, from: &amp;S::Address, to: &amp;S::Address, token_id: &amp;TokenId, amount: u64, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;()&gt; {
    let balance = self.balances
        .get(&amp;(from, token_id), state)
        .context("Failed to read sender balance")?
        .unwrap_or(0);
    
    if balance &lt; amount {
        // User-facing error message
        return Err(anyhow::anyhow!("Insufficient balance: {} &lt; {}", balance, amount));
    }
    
    let new_balance = balance - amount;
    
    // Add context for debugging when operations fail
    self.balances
        .set(&amp;(from, token_id), &amp;new_balance, state)
        .with_context(|| format!("Failed to update balance for {} token {}", from, token_id))?;
    
    // ... rest of transfer logic
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<p>Transaction reverts are normal and expected - log them at <code>debug!</code> level if needed for debugging, not as warnings or errors.</p>
<h2 id="native-only-code-and-custom-apis"><a class="header" href="#native-only-code-and-custom-apis">Native-Only Code and Custom APIs</a></h2>
<p>Some functionality should only run natively on the full nodes, not in the zkVM during proof generation. This is a critical concept for separating verifiable on-chain logic from off-chain operational tooling.</p>
<p>Any code that shouldn't be part of the state transition verification must be gated with <code>#[cfg(feature = "native")]</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "native")]
impl&lt;S: Spec&gt; MyModule&lt;S&gt; {
    // This code only compiles natively, not in zkVM
    pub fn debug_state(&amp;self, state: &amp;impl StateAccessor&lt;S&gt;) {
        // ...
    }
}
<span class="boring">}</span></code></pre></pre>
<p>This ensures that your zk-proofs remain small and your on-chain logic remains deterministic. Common use cases for native-only code include:</p>
<ul>
<li>Custom REST APIs and RPC methods</li>
<li>Metrics and logging integration</li>
<li>Debugging tools</li>
<li>Integrations with external services</li>
</ul>
<h3 id="adding-custom-rest-apis"><a class="header" href="#adding-custom-rest-apis">Adding Custom REST APIs</a></h3>
<p>You can easily add custom APIs to your module by implementing the
<code>HasCustomRestApi</code> trait. This trait has two methods - one which actually
implements the routes, and an optional one which provides an <code>OpenApi</code> spec. You
can see a good example in the <code>Bank</code> module:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![cfg(feature = "native")]
<span class="boring">fn main() {
</span>impl&lt;S: Spec&gt; HasCustomRestApi for Bank&lt;S&gt; {
    type Spec = S;

    fn custom_rest_api(&amp;self, state: ApiState&lt;S&gt;) -&gt; axum::Router&lt;()&gt; {
        axum::Router::new()
            .route(
                "/tokens/:tokenId/total-supply",
                get(Self::route_total_supply),
            )
            .with_state(state.with(self.clone()))
    }

    fn custom_openapi_spec(&amp;self) -&gt; Option&lt;OpenApi&gt; {
        let mut open_api: OpenApi =
            serde_yaml::from_str(include_str!("../openapi-v3.yaml")).expect("Invalid OpenAPI spec");
        for path_item in open_api.paths.paths.values_mut() {
            path_item.extensions = None;
        }
        Some(open_api)
    }
}

async fn route_balance(
    state: ApiState&lt;S, Self&gt;,
    mut accessor: ApiStateAccessor&lt;S&gt;,
    Path((token_id, user_address)): Path&lt;(TokenId, S::Address)&gt;,
) -&gt; ApiResult&lt;Coins&gt; {
    let amount = state
        .get_balance_of(&amp;user_address, token_id, &amp;mut accessor)
        .unwrap_infallible() // State access can't fail because no one has to pay for gas.
        .ok_or_else(|| errors::not_found_404("Balance", user_address))?;

    Ok(Coins { amount, token_id }.into())
}
<span class="boring">}</span></code></pre></pre>
<p>REST API methods get access to an <code>ApiStateAccessor</code>. This special struct gives
you access to both normal and <code>Accessory</code> state values. You can freely read and
write to state during your API calls, which makes it easy to reuse code from the
rest of your module. However, it's important to remember API calls do <em>not</em>
durably mutate state. Any state changes are thrown away at the end of the
request.</p>
<p>If you implement a custom REST API, your new routes will be automatically nested
under your module's router. So, in the following example, the
<code>tokens/:tokenId/total-supply</code> function can be found at
<code>/modules/bank/tokens/:tokenId/total-supply</code>. Similarly, your OpenApi spec will
get combined with the auto-generated one automatically.</p>
<p>Note that for for custom REST APIs, you'll need to manually write an <code>OpenApi</code>
specification if you want client support.</p>
<h3 id="legacy-rpc-support"><a class="header" href="#legacy-rpc-support">Legacy RPC Support</a></h3>
<p>In addition to custom RESTful APIs, the Sovereign SDK lets you create JSON-RPC
methods. This is useful to provide API compatibility with existing chains like
Ethereum and Solana, but we recommend using REST APIs whenever compatibility
isn't a concern.</p>
<p>To implement RPC methods, simply annotate an <code>impl</code> block on your module with
the <code>#[rpc_gen(client, server)]</code> macro, and then write methods which accept an
<code>ApiStateAcessor</code> as their final argument and return an <code>RpcResult</code>. You can see
some examples in the <a href="fix-link"><code>Evm</code> module</a>.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span>#![cfg(feature = "native")]
<span class="boring">fn main() {
</span>#[rpc_gen(client, server)]
impl&lt;S: Spec&gt; Evm&lt;S&gt; {
    /// Handler for `net_version`
    #[rpc_method(name = "eth_getStorageAt")]
    pub fn get_storage_at(
        &amp;self,
        address: Address,
        index: U256,
        state: &amp;mut ApiStateAccessor&lt;S&gt;,
    ) -&gt; RpcResult&lt;U256&gt; {
        let storage_slot = self
            .account_storage
            .get(&amp;(&amp;address, &amp;index), state)
            .unwrap_infallible()
            .unwrap_or_default();
        Ok(storage_slot)
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="mastering-your-module"><a class="header" href="#mastering-your-module">Mastering Your Module</a></h3>
<p>By leveraging Hooks, robust error handling, and custom APIs, you can build sophisticated, production-grade modules that are both powerful and easy to operate.</p>
<p>With a deep understanding of module implementation, you may next want to optimize your rollup's performance. The next section on "Understanding Performance" will dive into state access patterns and cryptographic considerations that can significantly impact your application's throughput.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="understanding-performance"><a class="header" href="#understanding-performance">Understanding Performance</a></h1>
<h3 id="state-access"><a class="header" href="#state-access">State Access</a></h3>
<p>The vast majority of the cost of executing a Sovereign SDK transaction comes from state accesses. When calling <code>item.set(&amp;value)</code>, the SDK serializes your value and stores the bytes in cache. When time you access a value using <code>item.get()</code>, the SDK deserializes a fresh copy of your value from the bytes held in cache, falling back to disk if necessary.</p>
<p>Each time you access a value that's not in cache, the SDK has to generate a merkle proof of the value, which it will consume when it's time to generate a zero-knowledge proof. Similarly, each time you write a new value, the SDK has to generate a merkle update proof. This makes reading/writing to a <code>hot</code> value at least an order of magnitude cheaper than writing to a <code>cold</code> one (where <code>hot</code> means that the value has already been accessed in the current block.) So, if you have state items that are frequently accessed together, it's a good idea to bundle them into a single <code>StateValue</code> or store them under the same key in a <code>StateMap</code>.</p>
<p>As a rule of thumb, for each 10% locality, you should be willing to add an extra 200 bytes to your <code>StateValue</code>. In other words, if two values are accessed together 30% of the time, you should put them together unless either of the state items is bigger than 600 bytes. (Exception: If two items are always accessed together, you should always group them together - no questions asked).</p>
<h3 id="cryptography"><a class="header" href="#cryptography">Cryptography</a></h3>
<p>The other common source of performance woes is heavy-duty cryptography. If you need to do any cryptographic operations, check whether the <code>Spec</code> trait provides a method in its <code>Spec::CryptoSpec</code> that already does what you want. If it does, use that - the SDK will ensure you get an implementation which is optimized for the SDK's peculiar requirements. If you need access to more exotic cryptography, you can use pretty much any existing Rust library - but be aware that the performance penalty might be severe when it comes time to prove your module's execution, which could limit your total throughput. If you do need advanced cryptography, you may need to pick an implementation that's suited to a particular <code>ZKVM</code> (like <code>SP1</code> or <code>Risc0</code>) and only use that vm with your module.</p>
<h3 id="building-for-scale"><a class="header" href="#building-for-scale">Building for Scale</a></h3>
<p>By keeping these performance principles in mind, bundling hot state and using optimized cryptography, you can design your modules to be highly efficient, ensuring your rollup can scale to meet user demand.</p>
<p>While building custom logic is powerful, you don't always have to start from scratch. The Sovereign SDK comes with a rich set of "Prebuilt Modules" for common tasks like token management, bridging, and sequencer orchestration. The next section provides an overview of these modules, which you can leverage to accelerate your development.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="prebuilt-modules"><a class="header" href="#prebuilt-modules">Prebuilt Modules</a></h1>
<p>Here's a comprehensive list of all existing modules:</p>
<h3 id="user-facing"><a class="header" href="#user-facing">User Facing</a></h3>
<p><a href="fix-link"><strong>sov-bank</strong></a> - Token management module for
creating, transferring, and burning tokens
with unique addresses and names</p>
<p><a href="fix-link"><strong>sov-chain-state</strong></a> - Provides access to
blockchain state including block height, hash,
and general chain information</p>
<p><a href="fix-link"><strong>sov-paymaster</strong></a> - Enables third-party gas
sponsorship with per-sequencer payer
configuration, so that users don't need any gas
tokens to start transacting on your rollup</p>
<p><a href="fix-link"><strong>sov-evm</strong></a> - EVM compatibility layer that
processes RLP-encoded Ethereum transactions
and provides standard Ethereum endpoints</p>
<p><a href="fix-link"><strong>sov-svm</strong></a> - SVM compatibility layer that
processes Solana transactions
and provides standard Solana endpoints (built &amp; maintained by the <a href="https://www.termina.technology/">Termina</a> team)</p>
<h3 id="bridging"><a class="header" href="#bridging">Bridging</a></h3>
<p><a href="fix-link"><strong>sov-hyperlane-mailbox</strong></a> - All five of these modules are
part of the Hyperlane (bridging) integration. They enable
any Sovereign SDK rollup to bridge messages and tokens from
any EVM, SVM or Cosmos SDK chain.</p>
<ul>
<li><a href="fix-link"><strong>Mailbox</strong></a>: Sends and receives cross-chain
messages</li>
<li><a href="fix-link"><strong>MerkleTreeHook</strong></a>: Computes merkle root of
sent messages</li>
<li><a href="fix-link"><strong>InterchainGasPaymaster</strong></a>: Handles
cross-chain fee payments to relayers</li>
<li><a href="fix-link"><strong>Warp</strong></a>: Enables interchain token transfers
<ul>
<li>Supports validator announcements and
multisig ISMs</li>
</ul>
</li>
</ul>
<h3 id="core"><a class="header" href="#core">Core</a></h3>
<p><a href="fix-link"><strong>sov-accounts</strong></a> - Account management system
that automatically creates addresses for
first-time senders and manages
credential-to-address mappings</p>
<p><a href="fix-link"><strong>sov-uniqueness</strong></a> - Transaction deduplication
logic using either nonce-based (Ethereum-style) or
generation-based methods (for low-latency applications)</p>
<p><a href="fix-link"><strong>sov-blob-storage</strong></a> - Deferred blob storage
system implementing the BlobSelector rollup
capability (which enables soft-confirmations
without losing censorship resistance)</p>
<h3 id="incentive--economics"><a class="header" href="#incentive--economics">Incentive &amp; Economics</a></h3>
<p><a href="fix-link"><strong>sov-attester-incentives</strong></a> - Complete
attestation/challenge verification workflow
with bonding and rewards for optimistic
rollups</p>
<p><a href="fix-link"><strong>sov-prover-incentives</strong></a> - Prover
registration, proof validation, slashing, and
rewards distribution</p>
<p><a href="fix-link"><strong>sov-sequencer-registry</strong></a> - Manages sequencer
registration, slashing, and rewards</p>
<p><a href="fix-link"><strong>sov-revenue-share</strong></a> - Manages automated revenue sharing</p>
<h3 id="development--testing"><a class="header" href="#development--testing">Development &amp; Testing</a></h3>
<p><a href="fix-link"><strong>sov-synthetic-load</strong></a> - Load testing module
exposing heavy transaction types for
performance testing</p>
<p><a href="fix-link"><strong>sov-value-setter</strong></a> - Simple testing module
for storing and retrieving a single value</p>
<p><a href="fix-link"><strong>module-template</strong></a> - Starter template
demonstrating proper module structure with
state-changing methods and queries</p>
<h3 id="standing-on-the-shoulders-of-giants"><a class="header" href="#standing-on-the-shoulders-of-giants">Standing on the Shoulders of Giants</a></h3>
<p>Leveraging these prebuilt modules can save you significant development time and effort, allowing you to focus on your application's unique business logic. You've now completed the "Writing Your Application" chapter and have a comprehensive understanding of how to build, test, and deploy powerful rollups.</p>
<p>The next major part of our book, "Instrumenting Your Rollup," will shift focus from development to operations, teaching you how to monitor your running rollup using metrics and structured logging.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="instrumenting-your-rollup"><a class="header" href="#instrumenting-your-rollup">Instrumenting Your Rollup</a></h1>
<p>Proper instrumentation is essential for monitoring, debugging, and optimizing your rollup in production. The Sovereign SDK provides comprehensive observability tools that help you understand your rollup's behavior and performance.</p>
<p>This section covers:</p>
<ul>
<li><strong><a href="/instrumenting/metrics.html">Metrics</a></strong> - Track performance indicators and business metrics</li>
<li><strong><a href="/instrumenting/logging.html">Logging</a></strong> - Debug and monitor your rollup's execution</li>
</ul>
<p>[TODO: Insert section on spinning up Grafana dashboards to monitor your rollup seamlessly]</p>
<h2 id="important-native-only-features"><a class="header" href="#important-native-only-features">Important: Native-Only Features</a></h2>
<p>All instrumentation code must be gated with <code>#[cfg(feature = "native")]</code> to ensure it only runs on full nodes, not in the zkVM during proof generation. This allows you to instrument generously without affecting proof generation performance.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="metrics"><a class="header" href="#metrics">Metrics</a></h1>
<p>The SDK includes a custom metrics system called <a href="fix-link"><code>sov-metrics</code></a> designed specifically for rollup monitoring. It uses the <a href="https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/">Telegraf line protocol</a> format and integrates with Telegraf through socket listeners for efficient data collection. Metrics are automatically timestamped and sent to your configured Telegraf endpoint, which typically forwards them to InfluxDB for storage and Grafana for visualization. Metrics can only be tracked in <strong>native mode</strong> (not in zkVM).</p>
<p><strong>Important</strong>: Metrics are emitted immediately when tracked and are NOT rolled back if a transaction reverts. This means failed transactions will still have their metrics recorded, which can be useful for debugging and monitoring error rates.</p>
<h2 id="basic-example"><a class="header" href="#basic-example">Basic Example</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "native")]
use sov_metrics::{track_metrics, start_timer, save_elapsed};

impl&lt;S: Spec&gt; MyModule&lt;S&gt; {
    fn process_batch(&amp;self, items: Vec&lt;Item&gt;) -&gt; Result&lt;()&gt; {
        // Time the operation using the provided macros
        start_timer!(batch_timer);
            
        for item in items {
            self.process_item(item)?;
        }
            
        save_elapsed!(elapsed SINCE batch_timer);

        #[cfg(feature = "native")] 
        {
            // Track batch size
            track_metrics(|tracker| {
                tracker.submit_inline(
                    "mymodule_batch_size",
                    format!("items={}", items.len()),
                );
            });
            
            // Track processing time
            track_metrics(|tracker| {
                tracker.submit_inline(
                    "mymodule_batch_processing_time",
                    format!("duration_ms={}", elapsed.as_millis()),
                );
            });
        }
        
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="tracking-custom-metrics"><a class="header" href="#tracking-custom-metrics">Tracking Custom Metrics</a></h2>
<p>To track custom metrics, implement the <code>Metric</code> trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Implement your custom metric in a file of your own choosing...
#![cfg(feature = "native")]
use sov_metrics::Metric;
use sov_metrics::{track_metrics, start_timer, save_elapsed};
use std::io::Write;

#[derive(Debug)]
struct TransferMetric {
    from: String,
    to: String,
    token_id: TokenId,
    amount: u64,
    duration_ms: u64,
}

impl Metric for TransferMetric {
    fn measurement_name(&amp;self) -&gt; &amp;'static str {
        "mymodule_transfers"
    }
    
    fn serialize_for_telegraf(&amp;self, buffer: &amp;mut Vec&lt;u8&gt;) -&gt; std::io::Result&lt;()&gt; {
        // Format: measurement_name,tag1=value1,tag2=value2 field1=value1,field2=value2
        write!(
            buffer,
            "{},from={},to={},token_id={} amount={},duration_ms={}",
            self.measurement_name(),
            self.from,
            self.to,
            self.token_id,
            self.amount,
            self.duration_ms
        )
    }
}

// In your module file...
#[cfg(feature = "native")]
use sov_metrics::{track_metrics, start_timer, save_elapsed};
#[cfg(feature = "native")]
use my_custom_metrics::TransferMetric;

// Adapted from Bank module 
impl&lt;S: Spec&gt; Bank&lt;S&gt; {
    fn transfer(&amp;self, from: &amp;S::Address, to: &amp;S::Address, token_id: &amp;TokenId, amount: u64, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;()&gt; {

        start_timer!(transfer_timer);
        
        // Perform the transfer
        self.do_transfer(from, to, token_id, amount, state)?;
        
        save_elapsed!(elapsed SINCE transfer_timer);
        
        #[cfg(feature = "native")]
        {
            // Track your custom metric
            track_metrics(|tracker| {
                tracker.submit_metric(TransferMetric {
                    from: from.to_string(),
                    to: to.to_string(),
                    token_id: token_id.clone(),
                    amount,
                    duration_ms: elapsed.as_millis() as u64,
                });
            });
        }
        
        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="best-practices"><a class="header" href="#best-practices">Best Practices</a></h2>
<p>Note: While the SDK provides comprehensive metrics infrastructure, individual modules in the SDK don't currently use metrics directly. Most metrics are tracked at the system level (runner, sequencer, state transitions). The examples here show how you <em>could</em> add metrics to your custom modules.</p>
<ol>
<li><strong>Always gate with <code>#[cfg(feature = "native")]</code></strong> - Metrics are not available in zkVM</li>
<li><strong>Use meaningful measurement names</strong>
<ul>
<li>A lot of the packages that Sovereign SDK runs under the hood emit metrics.
To make it easy to discern that the metrics come from a Sovereign SDK component, we
follow the pattern of <code>sov_</code> in our metric names. We recommend following the
pattern <code>sov_user_module_name_metric_type</code> so that it's easy to discern user level
metric types.</li>
</ul>
</li>
<li><strong>Separate tags and fields properly</strong>:
<ul>
<li><a href="https://docs.influxdata.com/influxdb/cloud/reference/syntax/line-protocol/#elements-of-line-protocol">Telegraf line protocol discerns between Tags and Fields by separating them with a single whitespace</a>. Make sure to write your metrics accordingly.</li>
<li>Tags: Categorical values for filtering (types, status, enum variants), both their keys and values can only be strings</li>
<li>Fields: Numerical values you want to aggregate (counts, durations, amounts), their keys can be strings, and values can be one of: floats, integers, unsigned integers, strings, and booleans</li>
</ul>
</li>
<li><strong>Track business-critical metrics</strong>:
<ul>
<li>Transaction volumes and types</li>
<li>Processing times for key operations</li>
<li>Error rates and types</li>
</ul>
</li>
<li><strong>Avoid high-cardinality tags</strong> - Don't use unique identifiers like transaction hashes as tags</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="logging"><a class="header" href="#logging">Logging</a></h1>
<p>The SDK uses the <a href="https://docs.rs/tracing/latest/tracing/"><code>tracing</code></a> crate for structured logging, providing rich context and efficient filtering.</p>
<p><strong>Important</strong>: Logs are emitted immediately when generated and are NOT rolled back if a transaction reverts. This means failed transactions will still have their logs recorded, which is useful for debugging or monitoring why transactions failed.</p>
<h2 id="basic-logging-patterns"><a class="header" href="#basic-logging-patterns">Basic Logging Patterns</a></h2>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Adapted from the `Bank` module
use tracing::trace;

impl&lt;S: Spec&gt; MyModule&lt;S&gt; {
    pub(crate) fn freeze(
        &amp;mut self,
        token_id: TokenId,
        context: &amp;Context&lt;S&gt;,
        state: &amp;mut impl TxState&lt;S&gt;,
    ) -&gt; Result&lt;()&gt; {
        // Logging at the start of operation
        trace!(freezer = %sender, "Freeze token request");

        // Redundant code elided here...

        token
            .freeze(sender)
            .with_context(|| format!("Failed to freeze token_id={}", &amp;token_id))?;

        self.tokens.set(&amp;token_id, &amp;token, state)?;

        // Logging at the end of operation
        trace!(
            freezer = %sender,
            %token_id,
            "Successfully froze tokens"
        );

        Ok(())
    }
}
<span class="boring">}</span></code></pre></pre>
<h2 id="using-spans-for-context"><a class="header" href="#using-spans-for-context">Using Spans for Context</a></h2>
<p>Spans are like invisible context that gets automatically attached to every log line within their scope. Instead of passing context like <code>batch_id</code> or <code>user_id</code> through every function call just so you can log it, you create a span at the top level and all logs within that span automatically include that context.</p>
<p>Think of spans as a way to say "everything that happens from here until the span ends is part of this operation." This is especially useful when debugging - you can filter logs by span fields to see everything that happened during a specific batch process or user request.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tracing::instrument;

// Example 1: Using the #[instrument] macro (easiest way)
#[instrument(skip(self, state, items))]  // skip large/non-Debug types
fn process_batch(&amp;self, batch_id: BatchId, items: Vec&lt;Item&gt;, state: &amp;mut impl TxState&lt;S&gt;) -&gt; Result&lt;()&gt; {
    // The #[instrument] macro automatically adds all function parameters (except skipped ones) to the span
    // So batch_id is automatically included in all logs within this function
    info!(item_count = items.len(), "Starting batch processing");
    
    for (idx, item) in items.iter().enumerate() {
        // This log will show: batch_id=123 item_id=456 "Processing item"
        trace!(item_index = idx, item_id = %item.id, "Processing item");
        self.process_single_item(item, state)?;
    }
    
    info!("Batch processing completed");
    Ok(())
}

// Example 2: Creating spans manually (when you need more control)
fn process_user_request(&amp;self, user_id: UserId, request: Request) -&gt; Result&lt;()&gt; {
    // Create a span with context that will be included in all logs
    let span = tracing::span!(
        tracing::Level::INFO,
        "user_request", // span name
        %user_id,
        request_type = %request.request_type()
    );
    
    // Enter the span - all logs from here will include user_id and request_type
    let _enter = span.enter();
    
    debug!("Validating request");
    self.validate_request(&amp;request)?;
    
    debug!("Processing request");
    self.process(&amp;request)?;
    
    info!("Request completed successfully");
    Ok(())
}
<span class="boring">}</span></code></pre></pre>
<h2 id="log-levels"><a class="header" href="#log-levels">Log Levels</a></h2>
<ul>
<li><code>error!</code> - Unrecoverable errors that affect module operation</li>
<li><code>warn!</code> - Recoverable issues or unusual conditions</li>
<li><code>info!</code> - High-level operations (tx processing, module lifecycle)</li>
<li><code>debug!</code> - Detailed operational data (state changes, intermediate values)</li>
<li><code>trace!</code> - Very detailed execution flow</li>
</ul>
<h2 id="best-practices-1"><a class="header" href="#best-practices-1">Best Practices</a></h2>
<ol>
<li>
<p><strong>Structure your logs</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good - structured, filterable
debug!(user = %address, action = "deposit", amount = %value, "Processing deposit");

// Avoid - unstructured string interpolation
debug!("Processing deposit for {} of amount {}", address, value);
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Include relevant context</strong>:</p>
<ul>
<li>Transaction/operation IDs</li>
<li>User addresses (when relevant)</li>
<li>Amounts and values</li>
<li>Error details</li>
<li>State transitions</li>
</ul>
</li>
<li>
<p><strong>Don't log transaction reverts as errors or warnings</strong>:
Transaction reverts are expected behavior. Log them at <code>debug!</code> level if needed for debugging:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>if balance &lt; amount {
    debug!(
        user = %sender,
        requested = %amount,
        available = %balance,
        "Transfer failed due to insufficient balance"
    );
    return Err(anyhow::anyhow!("Insufficient balance"));
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Keep frequently triggered logs at debug or trace level</strong>:
Any log that gets triggered by every call to your module should use <code>debug!</code> or <code>trace!</code> to avoid log spam:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Good - routine operations at trace level
trace!(method = "transfer", from = %sender, "Processing transfer request");

// Bad - routine operations at info level will spam logs
info!("Transfer request received");  // Don't do this for every call
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p><strong>Use conditional logging for expensive operations</strong>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[cfg(feature = "native")]
fn debug_state(&amp;self, state: &amp;impl StateAccessor&lt;S&gt;) {
    if tracing::enabled!(tracing::Level::TRACE) {
        let total_accounts = self.count_accounts(state);
        let total_balance = self.calculate_total_balance(state);
        trace!(
            %total_accounts,
            %total_balance,
            "Module state snapshot"
        );
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<p>Set log levels via environment variables:</p>
<pre><code class="language-bash">RUST_LOG=info,my_module=debug cargo run
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="advanced-features"><a class="header" href="#advanced-features">Advanced Features</a></h1>
<p>The Sovereign SDK includes many advanced features beyond the core functionality covered in this documentation.</p>
<p><strong>To learn more about implementing these features in your rollup, just shoot us a message in our <a href="https://join.slack.com/t/sovereigndevelopers/shared_invite/zt-39aolimfp-XsFK6dL6LhOFHhtXsD_kCA">support channel</a> or fill out our <a href="fix-link">partner form</a> and we'll reach out to you.</strong></p>
<h3 id="performance--reliability"><a class="header" href="#performance--reliability">Performance &amp; Reliability</a></h3>
<ul>
<li><strong>Configurable delays</strong> – Enable instant cancels &amp; oracle updates while throttling toxic flow</li>
<li><strong>Automatic sequencer fail-over</strong> – Seamless failover across data centers ensures your soft-confirmations survive even the worst outages</li>
<li><strong>Intra-block caching</strong> – Cache state that's repeatedly accessed throughout a block, eliminating redundant instantiation per transaction and significantly boosting performance</li>
<li><strong>Dev-ops tooling</strong> – Production-ready observability and deployment tools</li>
</ul>
<h3 id="integrations--compatibility"><a class="header" href="#integrations--compatibility">Integrations &amp; Compatibility</a></h3>
<ul>
<li><strong>Privy integration</strong> – Click-to-sign flow using Privy</li>
<li><strong>Ethereum or Solana addresses and wallet support</strong> – Use any address format or wallet you prefer</li>
<li><strong>Hyperlane integration</strong> – Bridge liquidity from any EVM, SVM, or Cosmos SDK chain</li>
<li><strong>Multiple DA layers</strong> – Run with Celestia, Bitcoin, Solana, or bring your own DA solution</li>
<li><strong>Multiple zkVM integrations</strong> – Leverage the zkVM that best suits your application's performance characteristics: Risc0, SP1 (or soon any other Rust-compatible zkVM)</li>
</ul>
<p>We're happy to help you leverage these features to build production-ready rollups tailored to your exact requirements.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sdk-contributors"><a class="header" href="#sdk-contributors">SDK Contributors</a></h1>
<p>This section provides an overview of the Sovereign SDK aimed at core
contributors to the framework. It describes the primary components of the SDK at
the level of Rust crates.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="transaction-lifecyle-overview"><a class="header" href="#transaction-lifecyle-overview">Transaction Lifecyle Overview</a></h1>
<p>The transaction lifecycle begins with a <em>user</em>. First, the user opens a frontend
and gets some information about the current state of the blockchain. Then, they
open their wallet and sign a message indicating what action they want to take.</p>
<p>Once a message is signed, it needs to be ordered before full nodes can execute
it, so the user's next step is to contact a <em>sequencer</em> to post the transaction
onto the DA layer.</p>
<p>The sequencer accepts a number of transactions and bundles them into a single
<em><code>Blob</code></em>, which he sends to the DA layer for inclusion. This <code>Blob</code> is
ultimately sent to a <code>Proposer</code> on the DA layer, who includes it in his block
and gets it approved by the DA layer's validator set. Once consensus is reached
on the DA layer block containing the sequencer's <code>Blob</code>, the full nodes of the
rollup parse its contents and execute the transactions, computing a new rollup
state.</p>
<p>Next, specialized actors ("provers" or "attesters") generate a proof of the new
rollup state and post it onto the <code>DA layer</code>. Finally, light clients of the
rollup (end-users and/or bridges on other blockchains) verify the proof and see
the results of the transaction.</p>
<p><img src="../assets/tx-lifecycle.png" alt="Diagram of the Transaction Lifecycle" /></p>
<h1 id="sdk-design-philosophy"><a class="header" href="#sdk-design-philosophy">SDK Design Philosophy</a></h1>
<p>Now that we've established the basic transaction lifecycle, we have the
background we need to really dig into the design of the Sovereign SDK.</p>
<p>At a high level, the design process for the SDK was essentially just tracing the
transaction lifecycle diagram and asking two questions at each step:</p>
<ul>
<li>"How do we implement this step so that we really 'inherit the security of the
L1'?"</li>
<li>"Within those constraints, how do we build the SDK to accommodate the broadest
range of use cases?"</li>
</ul>
<h2 id="step-1-retrieving-information"><a class="header" href="#step-1-retrieving-information">Step 1: Retrieving Information</a></h2>
<p>Before doing anything, users need to find out about the current state of the
rollup. How can we enable that?</p>
<p>At this step, we have several conflicting goals and constraints:</p>
<ul>
<li>We want the user's view of the rollup to be as up-to-date as possible</li>
<li>We want to provide the strongest possible guarantees that the user's view of
state is correct</li>
<li>We want to minimize costs for the rollup</li>
<li>Users may not be willing/able to download more than a few hundred kilobytes of
data or do any significant computation</li>
</ul>
<p>Obviously, it's not possible to optimize all of these constraints
simultaneously. So, in the Sovereign SDK, we allow developers some flexibility
to pick the appropriate tradeoffs for their rollups - and we give end-users
additional flexibility to choose the setup that works best for them.</p>
<p>In practice, that means that...</p>
<ul>
<li>Developers can choose between Optimistic and ZK rollups, trading transaction
cost for time-to-finality.</li>
<li>Users can choose between running a full node (instant state access, but
expensive), running a light client (slower state access, but much cheaper and
trustless) and trusting a full node (instant state access)</li>
</ul>
<h2 id="step-2-signing-transactions"><a class="header" href="#step-2-signing-transactions">Step 2: Signing Transactions</a></h2>
<p>The SDK supports several signing/verification modes. The standard choice for
interacting with Sovereign SDK chains is our custom <code>UniversalWallet</code>, which is
available as a Metamask snap and a Ledger app. The <code>UniversalWallet</code> integrates
tightly with the Sovereign SDK to render transactions in human-readable format.
However, many chains need compatibility with legacy formats like Ethereum RLP
transactions or Solana instructions</p>
<p>We've made the pragmatic choice to be as compatible as possible with existing
crypto wallets using our <code>RuntimeAuthenticator</code> abstraction. By implementing the
<code>RuntimeAuthenticator</code>trait, developers cab bring their own transaction
deserialization and authorization logic. Even better, we allow rollups to
support several different <code>Authenticator</code> implementations simultaneously. This
allows developers to retain backward compatibility with legacy transaction
formats, without compromising on support for their native functionality.</p>
<h2 id="step-3-sequencing"><a class="header" href="#step-3-sequencing">Step 3: Sequencing</a></h2>
<p>Once a user has signed a transaction, we need to broadcast it to all full nodes
of the rollup.</p>
<p>Since a primary design goal is to inherit the security of the underlying
blockchain, we want to ensure that users are always able to fall back on the
censorship resistance of the L1 if necessary. At the same time, we don't expect
users to interact directly with the underlying blockchain in the normal case.
The underlying blockchain will charge fees in its own token, and we don't need
or want users of the rollup to be thinking about exchange rates and L1 gas
limits.</p>
<p>We also need to protect the rollup from spam. In a standard blockchain, spam is
handled by ensuring that everyone pays for the computation that the network does
on their behalf. Transactions with invalid signatures are filtered out at the
peer-to-peer layer and never get included in blocks. This means that an attacker
wanting to spam the rollup has no asymmetric advantage. He can send invalid
transactions to the few nodes he happens to be directly connected to, but they
will just disconnect. The only way to get the <em>entire blockchain network</em> to
process a transaction is to provide a valid signature and pay enough gas fees to
cover the cost of execution.</p>
<p>In a rollup, things are different. Rollups <em>inherit</em> the consensus of an
underlying blockchain <em>which doesn't know about the transaction validity rules
of the rollup</em>. Since the underlying chain doesn't know the rules, it can't
enforce them. So, we need to be prepared to deal with the fact that the rollup's
ledger is <em>dirty</em>. This is bad news, because checking transaction signatures is
expensive - especially in zero-knowledge. If we aren't careful, an attacker
could flood the rollup's ledger with malformed transactions and force the entire
network to pay to check thousands of invalid signatures.</p>
<p>This is where the sequencer comes in. Sequencers accept transactions from users
and bundle them into <code>Blob</code>s, which get posted onto the L1. At the rollup level,
we force all sequencers to register by locking up some tokens - and we ignore
any transactions which aren't posted by a registered sequencer. If a sequencer's
bundle includes any transactions which have invalid signatures, we slash his
deposit and remove him from the registry. This solves two problems at once.
<em>Users</em> don't need to worry about obtaining tokens to pay for inclusion on the
DA layer, and <em>the rollup</em> gets builtin spam protection.</p>
<p>Unfortunately, this setup also gives sequencers a lot of power. Since the
sequencer handles transactions before they've gone through the DA layer's
consensus mechanism, he can re-order transactions - and potentially even halt
the rollup by refusing to publish new transactions.</p>
<p>To mitigate this power, we need to put a couple of safeguards in the protocol.</p>
<p>First, we allow anyone to register as a sequencer depositing tokens into the
sequencer registry. This is a significant departure from most existing rollups,
which rely on a single trusted sequencer.</p>
<p>Second, we allow sequencers to register <em>without sending a transaction through
an existing sequencer</em>. Specifically, we add a rule that the rollup will
consider up to <code>K</code> extra blobs from unregisterd sequencers in each rollup block.
If any of the first <code>K</code> "unregistered" blobs conform to a special format, then
the rollup will interpret them as requests to register a new sequencer. By
capping the number of unregistered blobs that we look at, we limit the
usefulness of unregistered blobs as a DOS vector while still ensuring that
honest sequencers can register relatively quickly in case of censorship.</p>
<p>Finally, we try to make sequencing competitive by distributing some of the fees
from each transaction to the sequencer who included it. This incentivizes new
sequencers to register if the quality of service is low.</p>
<hr />
<p>Ok, that was a lot of information. Let's recap.</p>
<p>In the Sovereign SDK, sequencers are middlemen who post transactions onto the DA
layer, but it's the DA layer which ultimately decides on the ordering of
transactions. Anyone can register as a sequencer, but sequencers expose
themselves to slashing if they include transactions with invalid signatures (or
certain other kinds of obvious spam).</p>
<p>That covers a huge chunk of sequencing. But there are still two topics we
haven't touched on: stateful validation, and soft confirmations.</p>
<h3 id="stateful-validation"><a class="header" href="#stateful-validation">Stateful Validation</a></h3>
<p>Up to this point, we've been talking about transactions as if they're always
either valid or invalid for all time, regardless of what's happening on the
rollup. But in the real world (especially when there are many sequencers),
that's not the case. To give just one example, it's entirely possible for an
account to burn through all of its funds with a single transaction, leaving
nothing to pay gas with the next time around. So, if two sequencers publish
blobs at about the same time, it's very possible that the first blob will cause
some tranasactions in the second one to become invalid.</p>
<p>This complicates our analysis. Previously, we assumed that a sequencer was
malicious if he caused any invalid transactions to be processed. That meant that
we could safely slash his deposit and move on whenever we encountered a
validation error. But now, we can't make that assumption. Otherwise, sequencers
would have to be extremely conservative about which transactions they included -
since a malicious (or confused) user could potentially cause a sequencer to get
slashed by sending conflicting transactions to two different sequencers at the
same time.</p>
<p>On the other hand, we don't want to let sequencers get away with including
transactions that they <em>know</em> are invalid. Otherwise, a malicious sequencer
could include invalid transactions "for free", causing the rollup to do a bunch
of wasted computation.</p>
<p>We address these issues by splitting transasction validation into two
categories. Stateless validation (i.e. signature checks) happens first, and
transactions which fail stateless validation are invalid <em>forever</em>. If a
sequencer includes a transaction which is statelessly invalid, then we know he's
malicious. After a transaction has passed stateless validation, we proceed to
make some stateful checks (i.e. checking that the transaction isn't a duplicate,
and that the account has enough funds to pay for gas). If these checks fail, we
charge the sequencer a small fee - just enough to cover the cost of the
validatoin.</p>
<p>This ensures that sequencers are incentivized to do their best to filter out
invalid transactions, and that the rollup never does any computation without
getting paid for it, without being unfairly punitive to sequencers.</p>
<h3 id="soft-confirmations"><a class="header" href="#soft-confirmations">Soft Confirmations</a></h3>
<p>Now that we've talked about the minimum requirements for sequencer, we move on
to soft-confirmations.</p>
<p>One of the biggest selling points of rollups today is the ability to tell users
the outcome of the tranaction instantly. Under the hood, this experience is
enabled by giving a single trusted sequencer a "lock" on the rollup state.
Because he holds the lock, the sequencer can run a local simulation to determine
the exact effect of a transaction <em>before</em> he posts it on the DA layer.</p>
<p>Unfortunately, this introduces a load bearing point of centralization. If the
centralized sequencer becomes unavailable (or is malicious), the rollup halts
and users have little recourse.</p>
<p>On existing rollups, this issue is somewhat mitigated by providing an "inbox" on
the DA layer where users can send special "forced withdrawal" transactions.
However, in most existing rollups these "forced" transactions are significantly
less powerful than ordinary ones. (Users are often limited to only withdrawing
funds) and the delay period before they are processed is long.</p>
<p>In the Sovereign SDK, we try to do better. Unfortunately, there's no way to
enable soft confirmations without giving some entity a lock on (some subset of)
the rollup state. So, this is exactly what we do. We allow rollup deployers to
specify some special "preferred sequencer", which has a partial lock on the
rollup state.</p>
<p>In order to protect users in case of a malicious sequencer, though, we make a
few additional changes to the rollup.</p>
<p>First, we separate the rollup state into two subsets, "user" space and "kernel"
space. The kernel state of the rollup is maintained programatically, and it
depends directly on the headers of the latest DA layer blocks. Inside of the
protected kernel state, the rollup maintains a list of all the blobs that have
appeared on the DA layer, and the block number in which they appeared.</p>
<p>Second, we prevent access to the kernel state of the rollup during transaction
execution. This prevents users from creating transactions that could
accidentally invalidate soft-confirmations given by the sequencer, as well as
preventing the sequencer from deleting forced transactions before they can be
processsed.</p>
<p>Finally, we add two new invariants:</p>
<ol>
<li>
<p>Every blob which appears on the (canonical) DA chain will be processed within
some fixed number of blocks</p>
</li>
<li>
<p>All "forced" (non-preferred) transactions will be processed in the order they
appeared on the DA layer</p>
</li>
</ol>
<p>To help enforce these invariants, we add a concept of a "visible" slot number.
The visible slot number is a nondecreasing integer which represents block number
that the preferred sequencer observed when he started building his current
bundle. Any "forced" blobs which appear on the DA layer are processed when the
visible slot number advances beyond the number of the <em>real</em> slot in which they
appeared.</p>
<p>Inside the rollup, we enforce that...</p>
<ul>
<li>
<p>The visible slot number never lags behind the real slot number by more than
some constant <code>K</code> slots</p>
<ul>
<li>This ensures that "forced" transactions are always processed in a reasonable
time frame</li>
</ul>
</li>
<li>
<p>The visible slot number increments by <em>at least</em> one every time the preferred
sequencer succesfully submits a blob. The sequencer may increment the virtual
slot by more than one, but the maximum increment is bounded by a small
constant (say, 10).</p>
</li>
<li>
<p>The visible slot number is never greater than the current (real) slot number</p>
</li>
<li>
<p>Transactions may only access information about the DA layer that was known at
the time of their <em>virtual</em> slot's creation. Otherwise, users could write
transactions whose outcome couldn't be predicted, making it impossible to give
out soft confirmations. - For example, a user could say
<code>if current_block_hash % 2 == 1 { do_something() }</code>, which has a different
outcome depending on exactly which block it gets included in. Since the rollup
sequencer is not the L1 block proposer, he doesn't know what block the
transaction will get included in! By limiting transactions to accessing
historical information, we avoid this issue.</p>
</li>
</ul>
<p>What all of this means in practice is that...</p>
<ul>
<li>The visible state never changes unless either the preferred sequencer submits
a batch, or a timeout occurs (i.e. the visible slot lags too far). This
ensures that the preferred sequencer always knows the exact state that he's
building on top of.</li>
<li>An honest sequencer wants to keep the virtual slot number as close to the real
slot number as possible. This way, he has more buffer to absorb downtime
without the state changing. This reduces the risk of soft-confirmations being
invalidated.</li>
<li>Honest sequencers can always give accurate soft confirmations, unless the DA
layer experiences a liveness failure lasting more than <code>K</code> slots.</li>
<li>Transactions can access information about the underlying blockchain with the
best latency that doesn't invalidate soft confirmations.</li>
</ul>
<h3 id="handling-preferred-sequencer-failure"><a class="header" href="#handling-preferred-sequencer-failure">Handling Preferred Sequencer Failure</a></h3>
<p>With the current design, the Sovereign SDK supports soft confirmations while
providing a reasonably powerful forced transaction mechanism. We also provide
some limited protection from a malicious sequencer. If the sequencer is
malicious, he can - at worst - delay transaction processing by some constant
number of blocks. He can't prevent forced transactions from being processed, and
he can't selectively delay transactions.</p>
<p>We also provide some limited protection if the preferred sequencer commits a
slashable offense. In this case, the rollup enters "recovery mode", where it
reverts to standard "based" sequencing (where all sequencer are equal). In this
mode, it advances the virtual slot number two-at-a-time until the rollup is
caught up, at which point the rollup behaves as if there had never been a
preferred sequencer.</p>
<p>In the future, we may also add slashing if the preferred sequencer gives
"soft-confirmations" which turn out to be invalid, but this requires some
additional design work.</p>
<h2 id="step-4-execution"><a class="header" href="#step-4-execution">Step 4: Execution</a></h2>
<p>Once a transaction is sequenced, the rollup needs to process it.</p>
<p>At a high level, a Sovereign SDK transaction goes through the following
sequence:</p>
<ol>
<li>
<p>(Stateless) Deserialization: Decoding the bytes of the transaction into
meaningful components (signature, ChainID, etc)</p>
</li>
<li>
<p>(Stateful) Pre-validation: Checking that the address which is claiming to
have authorized the transaction exists and retrieving its preferences for
authorization. For example, if the address is a multisig, fetch the set of
public keys and the minimum number of signatures.</p>
</li>
<li>
<p>(Usually Stateless) Authentication: Checking that the transaction is
authorized. For example, checking that the signatures are valid.</p>
</li>
<li>
<p>(Stateful) Authorization: Matching the results of the authentication and
pre-validation steps to decide whether to execute. This step also reserves
the funds to pay for gas used during transaction execution. --- State changes
up to this point are irreversable. State changes beyond this point are either
committed or reverted together</p>
</li>
<li>
<p>(Stateful) Pre-dispatch hook: This hook allows <em>all</em> modules to inspect the
transaction (and their own state) and do initialization before the
transaction is executed. For example, a wallet module might use this hook to
check the user's balance and store it for later retrieval. This hook may
abort the transaction and revert any state changes by returning an <code>Error</code>.</p>
</li>
<li>
<p>(Stateful) Execution: The transaction is dispatched to a <em>single</em> target
module for execution. That module may invoke other modules if necessary
during execution. If this call returns an error, all state changes from step
5 onward are reverted.</p>
</li>
<li>
<p>(Stateful) Post-dispatch hook: This hook allows <em>all</em> modules to inspect
their state and revert the transaction if necessary. If this call returns an
error, all state changes from step 5 onward are reverted.</p>
</li>
<li>
<p>(Stateful) Post-execution: After transaction execution, any unused gas is
refunded to the payer</p>
</li>
</ol>
<p>As described in the "Sequencing" documentation, sequencers are slashed if any of
the two stateless steps fail. If either of the stateful steps prior to execution
fail, the sequencer is penalized - but just enough to cover the cost of the work
that has been done. If the transaction fails during execution, the costs are
paid by the user (or whichever entity is sponsoring the gas cost of the
transaction.)</p>
<p>For more details on execution, see [TODO]</p>
<h2 id="step-5-proving"><a class="header" href="#step-5-proving">Step 5: Proving</a></h2>
<p>Once a transaction is executed, all of the rollup <em>full nodes</em> know the result
instantly. Light clients, on the other hand need proof. In this section, we'll
describe the different kinds of proof that the Sovereign SDK offers.</p>
<h3 id="zero-knowledge-proofs"><a class="header" href="#zero-knowledge-proofs">Zero-Knowledge Proofs</a></h3>
<p>The most powerful configuration for a rollup is zero-knowledge mode. In this
mode, light clients can trustlessly sync the chain with near-zero overhead and
only minutes of lag behind the chain tip. This enables fast and trustless
bridging between rollups, and between the rollup and the execution environment
of its DA layer (if applicable).</p>
<p>In the Sovereign SDK, proving is asynchronous (meaning that we post raw
<em>transactions</em> on the DA layer - so that full nodes can compute the rollup state
even before a proof is generated). This means that light clients have a view of
the state that lags a little bit behind full nodes.</p>
<h4 id="proof-statements"><a class="header" href="#proof-statements">Proof Statements</a></h4>
<p>All zero-knowledge proofs have the form, "I know of an input such that...". In
our case, the full statement is:</p>
<blockquote>
<p>I know of a DA layer block with hash X (where X is a public input to the
proof) and a rollup state root Y (where Y is another public input) such that
the rollup transitions to state Z (another public input) when you apply its
transaction processing rules.</p>
</blockquote>
<p>To check this proof, a client of the rollup needs to check that the input block
hash X corresponds to the next DA layer block, and that the input state root Y
corresponds to the current rollup state. If so, the client can advance its view
of the state from Y to Z.</p>
<p>This works great for a single block. But if a client needs to validate the
entire history of the rollup, checking proofs of each block would get expensive.
To alleviate this problem, we use recursive proofs to compress multiple block
proofs into one. (A nice property of zero-knowledge proofs is that the work to
verify a proof is roughly constant - so checking this recursive "aggregate"
proof is no more expensive than checking the proof of a single block.)</p>
<p>Each <code>AggregateProof</code> is a statement of the form:</p>
<blockquote>
<p>I know of a (previous) valid <code>AggregateProof</code> starting from <code>A</code> (the genesis
block hash, a public input) with state root <code>B</code> (the rollup's genesis state, a
public input) and ending at block hash <code>C</code> with state root <code>D</code>. And, I know of
a sequence of valid proofs such that...</p>
<ul>
<li>For each proof, the block header has the property that <code>header.prev_hash</code> is
the hash of the previous header</li>
<li>For each proof, the input state root is the output root of the previous
root.</li>
<li>The block header from the first proof has <code>prev_hash == C</code></li>
<li>The first proof has has input state root <code>D</code></li>
<li>The final proof in the chain has block hash <code>A</code> and output root <code>B</code> (where
<code>A</code> and <code>B</code> are public inputs)</li>
</ul>
</blockquote>
<h4 id="incentives"><a class="header" href="#incentives">Incentives</a></h4>
<p>Generating zero-knowledge proofs is expensive. So, if we want proofs to be
generated, we need to incentivize proof creation in protocol, preferrably using
the gas fees that users are already paying.</p>
<p>In a standard blockchain, the goal of transaction fees markets is to maximize
consumer surplus. They achieve this by allocating a scarce resource (blockspace)
to the people who value it most. Analysis shows that EIP-1559 is extremely good
at solving this optimization problem in the setting where supply is fixed and
demand varies rapidly. EIP-1559 adjusts the price of blockspace to the exact
price level at which demand matches supply.</p>
<p>In zk-rollups, we have a slightly different setup. Our supply of blockspace is
not constant. Instead, it's possible to invest more money in proving hardware in
order to increase the rollup's throughput. However, bringing more prover
capacity online takes time. Deals have to be negotiated, hardware provisioned,
etc. So, in the short term, we model prover capacity as being fixed - and we use
EIP-1559 to adjust demand to fit that target.</p>
<p>In the long run, we want to adjust the gas limit to reflect the actual capacity
of available provers. (Note that this is not yet fully implemented). To
facilitate this, we will track the rollup's gas usage and proving throughput
(measured in gas per second) over time. If rollup blocks are full and provers
are able to keep up, we will gradually increase the gas limit until blocks are
no longer full or provers start to fall behind.</p>
<p>This still leaves one problem... how do we incentivize provers to bring more
hardware online? After all, adding more hardware increases the gas limit, which
increases the supply of blockspace. This causes congestion (and fees) to fall,
increasing consumer surplus. But provers don't get paid in consumer surplus,
they get paid in fees. So, adding more hardware hurts <em>provers</em> in two ways. It
increases their costs, and it reduces the average fee level. This means that
provers are incentivized to provide as little capacity as possible.</p>
<p>The way we handle this problem is by introducing competition. In Sovereign, we
only reward the <em>first</em> prover to publish a valid proof of a block. Since
proving is almost perfectly parallel, and provers are racing to prove the block
first, a prover which adds slightly more capacity than its rivals experiences a
disproportionate increase in rewards. This should encourage provers to bring as
much capacity as possible.</p>
<p>Since we want to reward provers with funds on the rollup, we need consensus.
(Otherwise, it would be trivial to cause a chain split by creating a fork which
sent some rewards to a different prover.) So, we require provers to post their
proofs on chain. The first prover to post a valid proof of a particular block
gets rewarded with the majority of the <code>base_fee</code>s collected from that block.
This is a deviation from EIP-1559, where all base fees are burned. Intuitively,
our construction is still safe because provers "burn" money in electricity and
hardware costs in order to create proofs. However, we also burn a small
proportion of base fees as insurance in case proving costs ever fall to
negligble levels.</p>
<p>Once a prover has posted his proof on the DA layer, two things happen. First,
full nodes read the proof and, if it's valid reward the prover. If it's invalid,
the prover has his deposit slashed. (Just like a misbehaving sequencer. Also
like sequencers, data posted by un-bonded entities is ignored.) Second, light
clients of the rollup download and verify the proof, learning the state of the
rollup. As an implementation detail, we require proofs which get posted on chain
to be domain separated, so that light clients can download just the proofs from
a rollup without also needing to fetch all of the transaction data.</p>
<h4 id="summary-the-proving-workflow"><a class="header" href="#summary-the-proving-workflow">Summary: The proving workflow</a></h4>
<p>So, putting this all together, the proving workflow looks like this:</p>
<ol>
<li>
<p>A DA layer block is produced at height <code>N</code>. This block contains some rollup
transactions.</p>
</li>
<li>
<p>Full nodes immediately process the transactions and compute a new state.</p>
</li>
<li>
<p>Provers begin generating a proof of block <code>N</code>.</p>
</li>
<li>
<p>(About 15 minutes later) a prover creates a valid proof of block <code>N</code>. In the
meantime, DA layer blocks <code>N+1</code> through <code>N+X</code> have been produced.</p>
<p>a. At this point, full nodes are aware of rollup state <code>N+X</code>, while light
clients are still unaware of <code>N</code></p>
</li>
<li>
<p>The prover creates a new <code>AggregateProof</code>, which...</p>
<p>a. Proves the validity of the proof of block <code>N</code></p>
<p>b. Proves the validity of the previous <code>AggregateProof</code> (which covered the
rollup's history from genesis to block <code>N-1</code>)</p>
<p>c. Optionally proves the validity of proofs of blocks <code>N+1</code>, <code>N+2</code>, ...,
<code>N+X</code>, if such proofs are available. (Note that the <code>AggregateProof</code> must
cover a contiguous range of blocks starting from genesis, but it may cover
any number of blocks subject to that constraint.) For concreteness, suppose
that in this case the prover includes blocks <code>N+1</code> through <code>N+5</code>.</p>
</li>
<li>
<p>The prover posts the new <code>AggregateProof</code> onto the DA layer at some height -
call it <code>N+30</code>. At this point, full nodes are aware of state <code>N+30</code> (which
includes a reward for the prover), and light clients are aware of state
<code>N+5</code>. At some point in the future, a proof of <code>N+30</code> will be generated, at
which point light clients will become aware of the prover's reward.</p>
</li>
</ol>
<h3 id="optimistic-proofs"><a class="header" href="#optimistic-proofs">Optimistic Proofs</a></h3>
<p>For some rollups, generating a full zero-knowledge proof is too expensive. For
these applications, the Sovereign SDK offers Optimistic Mode, which allows
developers to trade some light-client latency for lower costs. With a zk-rollup,
light clients have a view of the state which lags behind by about 15 minutes
(the time it takes to generate a) zero- knowledge proof. However, at the end of
those 15 minutes, light clients know the state with cryptographic certainty.</p>
<p>In an optimistic rollup, light clients have a different experience. They get
some indication of the new rollup state very quickly (usually in the very next
block), but they need to wait much longer (usually about a day) to be sure that
their new view is correct. And, even in this case, clients only have
"cryptoeconomic" certainty about the new state.</p>
<h4 id="proving-setup"><a class="header" href="#proving-setup">Proving Setup</a></h4>
<p>In an optimistic rollup, the "proofs" checked by light clients are not (usually)
proofs at all. Instead, they are simple attestations. Attesters stake tokens on
claims like "the state of the rollup at height <code>N</code> is <code>X</code>", and anyone who
successfully challenges a claim gets to keep half of the staked tokens. (The
other half are burned to prevent an attester from lying about the state and then
challenging himself from another account and keeping his tokens). In exchange,
for their role in the process, attesters are rewarded with some portion of the
rollup's gas fees. This compensates attesters for the opportunity cost of
locking their capital.</p>
<p>This mechanism explains why light clients can know the state quickly with <em>some</em>
confidence right away, but they take time to reach full certainty. Once they've
seen an attestation to a state, clients know that either the state is correct,
or the attester is going to lose some amount of capital. As time goes by and no
one challenges the assertion, their confidence grows until it reaches (near)
certainty. (The point at which clients are certain about the outcome is usually
called the "finality period" or "finality delay".)</p>
<p>The previous generation of optimistic rollups (including Optimism and Arbitrum)
relies on running an on-chain bisection game over an execution trace to resolve
disputes about the rollup state. This requires $log_2(n)$ rounds of interaction,
where <code>n</code> is the length of the trace (i.e. a few hundred million). To handle the
possibility of congestion or censorship, rollups need to set the timeout period
of messages conservatively - which means that a dispute could take up to a week
to resolve.</p>
<p>In the Sovereign SDK, we resolve disputes by generating a zero-knowledge proof
of the outcome of the disputed block. Since this only requires one round of
interaction, we don't need the same challenge delay. However, we do need to
account for the fact that proving is a heavy process. Generating a proof might
take a few hours, and proving services might be experiencing congestion. To
minimize the risk, we plan to set the finality period conservatively at first
(about one day) and reduce it over time as we gain confidence.</p>
<p>Otherwise, the overall proving setup is quite similar to that of a zk-rollup.
Just as in zk-rollups, proofs (and attestations) are posted onto the DA layer so
that we have consensus about who to reward and who to slash. And, just like a
zk-rollup, optimistic proofs/attestations are posted into a separate "namespace"
on the DA layer (if possible) so that light clients can avoid downloading
transaction data. The only other significant distinction between optimistic and
zk rollups in Sovereign is that optimistic rollups use block-level proofs to
resolve disputes instead of generating aggregate proofs which go all the way to
genesis.</p>
<h2 id="conclusion"><a class="header" href="#conclusion">Conclusion</a></h2>
<p>In the Sovereign SDK, we try to provide security, flexibility, and performance
<em>in that order</em>.</p>
<p>As a contributor, it's your job to maintain that hierarchy. Security must always
come first. And in blockchain, security is mostly about incentives. Especially
in blockchain, you get what you incentivize. If your rollup under-prices some
valuable resource, you'll get spam. If you under pay for some service, that
service won't be provided reliably.</p>
<p>This is why incentive management is so deeply baked into the SDK. Every step -
from sequencing to proving to execution to finality - needs to be carefully
orchestrated to keep the incentives of the participants in balance.</p>
<p>Once the setup is secure, our next priority is enabling the broadest set of use
cases. We try to provide maximum flexibility, and abstract as much functionality
as possible into reusable components. You can read more about how we achieve
flexibility at the level of Rust code in the <a href="./abstractions.html">abstractions</a>
chapter.</p>
<p>Finally, we optimize performance. This means eliminating redundant computation,
carefully managing state access patterns, and considering the strengths and
weaknesses of zero-knowledge proofs systems.</p>
<p>Happy hacking!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="main-abstractions"><a class="header" href="#main-abstractions">Main Abstractions</a></h1>
<blockquote>
<p>This document provides an overview of the major abstractions offered by the
SDK.</p>
<ul>
<li>Rollup Interface (STF + DA service + DA verifier)</li>
<li>sov-modules (<code>Runtime</code>, <code>Module</code>, stf-blueprint w/ account abstraction,
state abstractions)</li>
<li>sov-sequencer</li>
<li>sov-db</li>
<li>Rockbound</li>
</ul>
</blockquote>
<p>One of the most important principles in the Sovereign SDK is modularity. We
believe strongly in separating rollups into their component parts and
communicating through abstract interfaces. This allows us to iterate more
quickly (since components are unaware of the implementation details of other
components), and it also allows us to reuse components in contexts which are
often quite different from the ones in which they were orginally designed.</p>
<p>In this chapter, we'll give a brief overview of the core abstractions of the
Sovereign SDK</p>
<h2 id="native-vs-zk-execution"><a class="header" href="#native-vs-zk-execution">Native vs. ZK Execution</a></h2>
<p>Perhaps the most fundamental abstraction in Sovereign is the separation between
<code>"native"</code> code execution (which computes a new rollup state) and zero-knowledge
<em>verification</em> of that state. Native execution is the experience you're used to.
In native execution, you have full access to networking, disk, etc. In native
mode, you typically trust data that you read from your own database, but not
data that comes over the network.</p>
<p>Zero-knowledge execution looks similar. You write normal-looking Rust code to do
CPU and memory operations - but under the hood, the environment is alien. In
zero-knowledge execution, disk and network operations are impossible. Instead,
all input is received from the (untrusted) machine generating the proof via a
special syscall. So if you make a call that looks like a network access, you
might not get a response from <code>google.com</code>. Instead, the prover will pick some
arbitrary bytes to give back to you. The bytes might correspond to an actual
response (i.e. if the prover is honest and made the network request for you) -
but they might also be specially crafted to deceive you. So, in zero-knowledge
mode, great care must be taken to avoid relying on unverified data from the
prover.</p>
<p>In the Sovereign SDK, we try to share code between the <code>"native"</code> full node
implementation and the zero-knowledge environment to the greatest extent
possible. This minimizes surface area for bugs. However, a full node necessarily
needs a lot of logic which is unnecessary (and undesirable) to execute in
zero-knowledge. In the SDK, such code is gated behind a <code>cargo</code> feature called
<code>"native"</code>. This code includes RPC implementations, as well as logic to
pre-process some data into formats which are easier for the zero-knowledge code
to verify.</p>
<h2 id="the-rollup-interface"><a class="header" href="#the-rollup-interface">The Rollup Interface</a></h2>
<p>If you squint hard enough, a zk-rollup is made of three separate components.
There's an underlying blockchain ("Data Availability layer"), a set of
transaction execution rules ("a State Transition Function") and a zero-knowledge
proof system (a "ZKVM" for zero-knowledge virtual machine). In the abstract, it
seems like it should be possible to take the same transaction processing logic
(i.e. the EVM) and deploy it on top of many different DA layers. Similarly, you
<em>should</em> be able to take the same execution logic and compile it down to several
different proof systems - in the same way that you can take the same code an run
it on Risc0 or SP1.</p>
<p>Unfortunately, separating these components can be tricky in practice. For
example, the OP Stack relies on an Ethereum smart contract to enforce its
censorship resistance guarantees - so, you can't easily take an OP stack rollup
and deploy it on a non-EVM chain.</p>
<p>In the Sovereign SDK, flexibility is a primary design goal. So we take care to
codify this separation of concerns into the framework from the very beginning.
With Sovereign, it's possible to run any <code>State Transition Function</code> alongside
any <code>Da Service</code> on top of any (rust-compatible) proof system and get a
functional rollup. The <code>rollup-interface</code> crate is what makes this possible.
Every other crate in the SDK depends on it, because it defines the core
abstractions that are shared between all SDK rollups.</p>
<p><img src="../assets/dependency-graph.png" alt="A digram showing how the rollup interface supports the entire Sovereign SDK" /></p>
<p>Inside of the rollup interface, the <code>native</code> vs zero-knowledge distinction
appears in numerous places. For example, the <code>DA layer</code> abstraction has two
components - a <code>DaService</code>, which runs as part of <code>native</code> full node execution
and provides methods for fetching data from the underlying blockchain; and
<code>DaVerifier</code>, which runs in zero-knowledge and verifies that the data being
executed matches the provided DA block header.</p>
<h3 id="how-it-works-1"><a class="header" href="#how-it-works-1">How it Works</a></h3>
<p>Essentially, the Sovereign SDK is just a generic function that does this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn run_rollup&lt;Da: DaService, Zk: Zkvm, Stf: StateTransitionFunction&gt;(self, da: Da, zkvm: Zk, business_logic: Stf) {
	loop {
		// Run some `native` code to get the data for execution
		let (block_data, block_header) = da.get_next_block();
		let (input_state, input_state_root) = self.db.get_state();
		// Run some zero-knowledge code to execute the block
		let proof = zkvm.prove(|| {
			// Check that the inputs match the provided commitments
			if !da.verify(block_data, block_header) || !input_state.verify(input_state_root) {
				panic!()
			};
			// Make the data commitments part of the public proof
			output!(block_header.hash(), input_state_root)
			let output_state_root = business_logic.run(block_data, input_state);
			// Add the output root to the public proof
			output!(output_state_root)
		});
		// Publish the proof onto the DA layer
		da.publish(proof);
	}
}
<span class="boring">}</span></code></pre></pre>
<p>As you can see, most of the heavy lifting is done by the DA layer, the <code>Zkvm</code>
and the rollup's business logic. The full node implementation is basically just
glue holding these components together.</p>
<h3 id="da"><a class="header" href="#da">DA</a></h3>
<p>As discussed above, the role of the DA layer is to order and publish data. To
integrate with the Sovereign SDK, a DA layer needs to provide implementations of
two core traits: <code>DaService</code> and <code>DaVerifier</code>.</p>
<h4 id="da-service"><a class="header" href="#da-service">DA Service</a></h4>
<p>The <code>DaService</code> trait is usually just a thin wrapper around a DA layer's
standard RPC client. This trait provides standardized methods for fetching data,
generating merkle proofs, and publishing data. Because it interacts with the
network, correct execution of this trait is <em>not</em> provable in zero-knowledge.</p>
<p>Instead, the work of verifying of the data provided by the <code>DaService</code> is
offloaded to the <code>DaVerifier</code> trait. Since the <code>DaService</code> runs only in <code>native</code>
code, its implementation is less concerned about efficiency than zero-knowledge
code. It's also easier to patch, since updating the <code>DaService</code> does <em>not</em>
require any light clients or bridges to update.</p>
<p>The <code>DaService</code> is the only component of the SDK responsible for publishing and
fetching data. The SDK's node does not currently have a peer-to-peer network of
its own. This dramatically simplifies the full node and reduces bandwidth
requirements.</p>
<h3 id="da-verifier"><a class="header" href="#da-verifier">DA Verifier</a></h3>
<p>The <code>DaVerifier</code> is the zero-knowledge-provable counterpart of the <code>DaService</code>.
It is responsible for checking that the (untrusted) private inputs to a proof
match the public commitment <em>as efficiently as possible</em>. It's common for the
<code>DaVerifier</code> to offload some work to the <code>DaService</code> (i.e. as computing extra
metadata) in order to reduce the amount of computation required by the
<code>DaVerifier</code>.</p>
<p>At the level of <code>Rust</code> code, we encode the relationship between the <code>DaVerifier</code>
and the <code>DaService</code> using a helper trait called <code>DaSpec</code> - which specifies the
types on which both interfaces operate.</p>
<h4 id="zero-knowledge-virtual-machine-zkvm"><a class="header" href="#zero-knowledge-virtual-machine-zkvm">Zero Knowledge Virtual Machine ("<code>Zkvm</code>")</a></h4>
<p>The <code>Zkvm</code> traits make a zk-snark system (like <code>Risc0</code> or <code>Sp1</code>) compatible with
the Sovereign SDK. Like the <code>DA layer</code>, we separate <code>Zkvm</code> traits into a
<code>native</code> and zk version, plus a shared helper.</p>
<p>The <code>ZkvmHost</code> trait describes how a <code>native</code> computer executes an <code>elf</code> file
(generated from <code>Rust</code> code) and generates a zero-knowledge proof. It also
describes how the <code>native</code> machine passes private inputs (the "witness") into
the execution.</p>
<p>The <code>ZkvmGuest</code> trait describes how a program running in zero-knowledge mode
accepts inputs from the host machine.</p>
<p>Finally, the <code>ZkVerifier</code> trait describes how a proof generated by the host is
verified. This trait is implemented by both the <code>Host</code> and the <code>Guest</code>, which is
how we represent that proofs must be verifiable <code>native</code>ly and recursively (i.e.
inside another SNARK.)</p>
<h4 id="state-transition"><a class="header" href="#state-transition">State Transition</a></h4>
<p>A <code>StateTransitionFunction</code> ("STF") is a trait which describes:</p>
<ol>
<li>
<p>How to initialize a rollup's state at genesis</p>
</li>
<li>
<p>How to apply the data from the DA layer to generate a new state</p>
</li>
</ol>
<p>In other words, the implementation of <code>StateTransitionFunction</code> is what defines
the rollup's "business logic".</p>
<p>In the Sovereign SDK, we define a generic full node which can run any STF. As
long as your logic implements the interface, we should be able to run it.</p>
<p>However, implementing the business logic of a rollup is <em>extremely</em> complicated.
While it's relatively easy to roll your own implementation of the <code>Da</code> or <code>Zkvm</code>
traits, building a secure STF from scratch is a massive undertaking. It's so
complex, in fact, that we assume no one will ever do it - andthe vast majority
of the Sovereign SDK's code is devoted to providing a generic implementation of
an STF that developers can customize. (This STF is what we call the Sovereign
module system, or sov-modules).</p>
<p>So if no one is ever going to implement the <code>StateTransitionFunction</code> interface,
why bother maintaining it at all? One reason is for flexibility. Just because we
don't expect anyone to roll their own STF doesn't mean that they won't. But a
bigger motivation is to keep concerns separate. By hiding the implementation
details of the rollup behind the STF interface, we build a firm abstraction
barrier between it and the full node. This means that we're free to make
breaking changes on either side of the wall (either in the node, or in the STF)
without worrying about breaking the other component.</p>
<h2 id="sov-modules"><a class="header" href="#sov-modules">Sov Modules</a></h2>
<p>Outside of the rollup interface, the most important abstraction is
<code>sov-modules</code>. <code>sov-modules</code> is a pre-built STF with pluggable... modules. It
does the heavy lifting of implementing a secure STF so that you can focus on the
core logic of your application.</p>
<h3 id="the-runtime"><a class="header" href="#the-runtime">The Runtime</a></h3>
<p>At the heart of any sov-modules rollup is the <code>Runtime</code>:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// An example runtime similar to the one used in our "standard" demo rollup
pub struct Runtime&lt;S: Spec&gt; {
    /// The Bank module implements fungible tokens, which are needed to charge `gas`
    pub bank: sov_bank::Bank&lt;S&gt;,
    /// The Sequencer Registry module is where we track which addresses can send batches to the rollup
    pub sequencer_registry: sov_sequencer_registry::SequencerRegistry&lt;S&gt;,
    /// The Prover Incentives module is where we reward provers who do useful work
    pub prover_incentives: sov_prover_incentives::ProverIncentives&lt;S&gt;,
    /// The Accounts module implements identities on the rollup. All of the other modules rely on it
	/// to link cryptographic keys to logical accounts
    pub accounts: sov_accounts::Accounts&lt;S&gt;,
	/// The NFT module provides an implementation of a non-fungible token standard. It's totally optional.
    pub nft: sov_nft_module::NonFungibleToken&lt;S&gt;,
    #[cfg_attr(feature = "native", cli_skip)]
    /// The EVM module lets the rollup run Ethereum smart contracts. It's totally optional.
    pub evm: sov_evm::Evm&lt;S, Da&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>At the highest level, a runtime is "just" a collection of all the modules which
are included in your rollup. Its job is to take <code>Transaction</code>s and dispatch them
to the appropriate module for execution.</p>
<p>Pretty much all rollups built with the <code>sov-modules</code> include the bank, the
sequencer registry, and the accounts module in their <code>Runtime</code>. They also
usually include one of <code>sov_prover_incentives</code> (if they're a zk-rollup) or
<code>sov_attester_incentives</code> (if they're an Optimistic rollup).</p>
<p>You may also have noticed that the <code>Runtime</code> is generic over a <code>Spec</code>. This
<code>Spec</code> describe the core types (addresses, hashers, cryptography) used by the
rollup and the DA layer. Making your runtime generic over a Spec means that you
can easily change DA layers, or swap any of the core primitives of your rollup.
For example, a rollup can trivially switch from Ed25519 to secp256k1 for its
signature scheme by changing the implementation of its <code>Spec</code> trait.</p>
<h3 id="modules"><a class="header" href="#modules">Modules</a></h3>
<p>"Modules" are the things that process transactions. For example, the <code>Bank</code>
module lets users transfer tokens to each other. And the <code>EVM</code> module implements
a full Ethereum Virtual Machine that can process any valid Ethereum transaction.</p>
<p>A <code>Module</code> is just a rust <code>struct</code> that implements two traits called <code>Module</code>
and <code>ModuleInfo</code>.</p>
<h4 id="the-module-trait"><a class="header" href="#the-module-trait">The <code>Module</code> trait</a></h4>
<p>The <code>Module</code> trait is like a simplified version of the
<code>StateTransitionFunction</code>. It describes how to initialize the module at the
rollup's genesis, and how the module processes <code>CallMessage</code>s received from
users (i.e. how it processes transactions)</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait Module {
	// -- Some associated type definitions are omitted here --
	/// Module defined argument to the call method.
    type CallMessage: Debug;

    /// Genesis is called when a rollup is deployed and can be used to set initial state values in the module.
    fn genesis(
        &amp;self,
        _config: &amp;Self::Config,
        _working_set: &amp;mut WorkingSet&lt;Self::Spec&gt;,
    ) -&gt; Result&lt;(), ModuleError&gt;;

    /// Processes a transaction, updating the rollup state.
    fn call(&amp;self,
        _message: Self::CallMessage,
        _context: &amp;Context&lt;Self::Spec&gt;,
        _state: &amp;mut impl TxState&lt;S&gt;,
    ) -&gt; Result&lt;CallResponse, ModuleError&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>You'll notice that the <code>call</code> function takes three arguments: an associated
<code>CallMessage</code> type, a <code>Context</code>, and a <code>WorkingSet</code>.</p>
<ul>
<li>
<p>The <code>CallMessage</code> type is the deserialized content of the user's transaction -
and the module can pick any type to be its <code>CallMessage</code>. In most cases,
modules use an <code>enum</code> with one variant for each action a user might want to
take. For example, the <code>Bank::CallMessage</code> type has variants for minting,
transferring, and burning tokens.</p>
</li>
<li>
<p>The <code>Context</code> type is relatively straightforward. It simply contains the
address of the sequencer, who published the transaction, the identity of the
transaction's signer, and the current block height.</p>
</li>
<li>
<p>The <code>TxState</code> is the most interesting of the three, but it needs a little bit
of explanation. In the Sovereign SDK, the rust <code>struct</code> which implements a
<code>Module</code> doesn't actually contain any state. Rather than holding actual
values, the module simply defines the <em>structure</em> of some items in state. All
of the actual state of the rollup is stored in the <code>State</code> object, which is
in-memory layer on top of the rollup's database (in native mode) or merkle
tree (in zk mode). The <code>State</code> abstraction handles commit/revert semantics for
you, as well as taking responsibility for caching, deduplication, and
automatic witness generation/checking. It also provides utilities for charging
<code>gas</code> and emitting <code>event</code>s.</p>
</li>
</ul>
<p>The <code>Accounts</code> module provides a good example of a standard <code>Module</code> trait
implementation.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub enum CallMessage&lt;S: Spec&gt; {
    /// Updates a public key for the corresponding Account.
    /// The sender must be in possession of the new key.
    UpdatePublicKey(
        /// The new public key
        &lt;S::CryptoSpec as CryptoSpec&gt;::PublicKey,
        /// A valid signature from the new public key
        &lt;S::CryptoSpec as CryptoSpec&gt;::Signature,
    ),
}

impl&lt;S: Spec&gt; sov_modules_api::Module for Accounts&lt;S&gt; {
	// -- Some items ommitted here --
    fn call(
        &amp;self,
        msg: Self::CallMessage,
        context: &amp;Context&lt;S&gt;,
        working_set: &amp;mut WorkingSet&lt;S&gt;,
    ) -&gt; Result&lt;sov_modules_api::CallResponse, Error&gt; {
        match msg {
            call::CallMessage::UpdatePublicKey(new_pub_key, sig) =&gt; {
				// Find the account of the sender
				let pub_key = self.public_keys.get(context.sender(), working_set)?;
				let account = self.accounts.get(&amp;pub_key, working_set);
				// Update the public key
				self.accounts.set(&amp;new_pub_key, &amp;account, working_set);
				self.public_keys
					.set(context.sender(), &amp;new_pub_key, working_set);
				Ok(Default::default())
            }
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h4 id="the-moduleinfo-trait"><a class="header" href="#the-moduleinfo-trait">The <code>ModuleInfo</code> trait</a></h4>
<p>The <code>ModuleInfo</code> trait describes how the module interacts with the broader
module <em>system</em>. Each module has a unique ID and stores its state under a unique
<code>prefix</code> of the global key-value store provided by <code>sov-modules</code></p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub trait ModuleInfo {
    /// Returns id of the module.
    fn id(&amp;self) -&gt; &amp;ModuleId;

    /// Returns the prefix where module state is stored.
    fn prefix(&amp;self) -&gt; ModulePrefix;

    /// Returns addresses of all the other modules this module is dependent on
    fn dependencies(&amp;self) -&gt; Vec&lt;&amp;ModuleId&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>Unlike the <code>Module</code> trait, its incredibly rare for developers to implement
<code>ModuleInfo</code> by hand. Instead, it's strongly recommended to derive the
<code>ModuleInfo</code> using our handy macro. A typical usage looks like this:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(ModuleInfo, Clone)]
pub struct Bank&lt;S: sov_modules_api::Spec&gt; {
    /// The id of the sov-bank module.
    #[id]
    pub(crate) id: ModuleId,

    /// The gas configuration of the sov-bank module.
    #[gas]
    pub(crate) gas: BankGasConfig&lt;S::Gas&gt;,

    /// A mapping of [`TokenId`]s to tokens in the sov-bank.
    #[state]
    pub(crate) tokens: sov_modules_api::StateMap&lt;TokenId, Token&lt;S&gt;&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>This code automatically generates a unique ID for the bank module and stores it
in the field of the module called <code>id</code>. It also initializes the <code>StateMap</code>
"<code>tokens</code>" so that any keys stored in the map will be prefixed the with module's
<code>prefix</code>. This prevents collisions in case a different module also declares a
<code>StateMap</code> where the keys are <code>TokenId</code>s.</p>
<h3 id="module-state"><a class="header" href="#module-state">Module State</a></h3>
<p>The Sovereign SDK provides three core abstractions for managing module state. A
<code>StateMap&lt;K, V&gt;</code> maps arbitrary keys of type <code>K</code> to arbitrary values of type
<code>V</code>. A <code>StateValue&lt;V&gt;</code> stores a value of type <code>V</code>. And a <code>StateVec&lt;V&gt;</code> store an
arbitrary length vector of type <code>V</code>. All three types require their arguments to
be serializable, since the values are stored in a merkle tree under the hood.</p>
<p>All three abstractions support changing the underlying encoding scheme but
default to <code>Borsh</code> if no alternative is specified. To override the default,
simply add an extra type parameter which implements the <code>StateCodec</code> trait. (i.e
you might write <code>StateValue&lt;Da::BlockHeader, BcsCodec&gt;</code> to use the <code>Bcs</code>
serialization scheme for block headers, since your library for DA layer types
might only support serde-compatible serializers).</p>
<p>All state values are accessed through <code>TxState</code>. For example, you always write
<code>my_state_value.get(&amp;mut state)</code> to fetch a value. It's also important to
remember that modifying a value that you read from state doesn't have any effect
unless you call <code>my_value.set(new, &amp;mut working_set)</code>.</p>
<h4 id="merkle-tree-layout"><a class="header" href="#merkle-tree-layout">Merkle Tree Layout</a></h4>
<p><code>sov-modules</code> currently uses a generic
<a href="https://github.com/penumbra-zone/jmt">Jellyfish Merkle Tree</a> for its
authenticated key-value store. (Generic because it can be configured to use any
32-byte hash function). In the near future, this JMT will be replaced with the
<a href="https://sovereign.mirror.xyz/jfx_cJ_15saejG9ZuQWjnGnG-NfahbazQH98i1J3NN8">Nearly Optimal Merkle Tree</a>
that is currently under development.</p>
<p>In the current implementation, the SDK implements storage by generating a unique
(human-readable) key for each <code>StateValue</code>, using the hash of that key as a path
in the merkle tree. For <code>StateMap</code>s, the serialization of the key is appended to
that path. And for <code>StateVec</code>s, the index of the value is appended to the path.</p>
<p>For example, consider the following module:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// Suppose we're in the file my_crate/lib.rs
#[derive(ModuleInfo, Clone)]
pub struct Example&lt;S: sov_modules_api::Spec&gt; {
    #[id]
    pub(crate) id: ModuleId,
    #[state]
    pub(crate) some_value: sov_modules_api::StateValue&lt;u8&gt;,
    #[state]
    pub(crate) some_vec: sov_modules_api::StateVec&lt;u64&gt;,
    #[state]
    pub(crate) some_map: sov_modules_api::StateMap&lt;String, String&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>The value of <code>some_value</code> would be stored at the path
<code>hash(b"my_crate/Example/some_value")</code>. The value of the key "hello" in
<code>some_map</code> would be stored at <code>hash(b"my_crate/Example/some_map/⍰hello")</code> (where
<code>⍰hello</code> represents the borsh encoding of the string "hello") etc.</p>
<p>However, this layout may change in future to provide better locality. For more
details... ask Preston, I guess.</p>
<h4 id="exotic-state-variants"><a class="header" href="#exotic-state-variants">Exotic State Variants</a></h4>
<p>In addition to the standard state store, we support two other kinds of state:</p>
<p><code>KernelStateValue</code>s or (maps/vecs) act identically to regular <code>StateValues</code>, but
they're stored in a separate merkle tree which is more tightly access
controlled. This mechanism allows the rollup to store data that is inaccessible
during transaction execution, which is necessary to enable soft-confirmations
without sacrificing censorship resistance. For more details, see the section on
soft-confirmations in the <a href="./transaction-lifecycle.html">transaction lifecycle</a>
documentation. The global "state root" returned by the <code>sov-modules</code> from the
<code>StateTransitionFunction</code> implementation is the hash of the kernel state root
with the regular state root. We do our best to hide this detail from users of
the SDK, though. Merkle proofs are automatically generated against the global
root, so users don't need to worry about which state trie there values are in.</p>
<p><code>AccessoryStateValue</code> or (map/vec) types are similar to <code>Kernel</code> types except
that their values are not <em>readable</em> from inside the state transition function
at all. Under the hood, these value are stored in the rollup's database <em>but not
in either merkle tree</em>. This is useful for creating data that will be served via
RPC but never accessed again during execution - for example, the transaction
receipts from an Ethereum block.</p>
<h3 id="the-stf-blueprint"><a class="header" href="#the-stf-blueprint">The STF Blueprint</a></h3>
<p>The last key component of a <code>sov-modules</code> rollup is the <code>stf-blueprint</code>. This
"blueprint" provides a generic implementation of a <code>StateTransitionFunction</code> in
terms of a <code>Runtime</code> (described above) and a <code>Kernel</code> (which provides
security-critical functionality like censorship resistance in a way that's
isolated from the transaction execution logic).</p>
<p>The STF blueprint implements the following high-level workflow:</p>
<ol>
<li>Take all of the new data <code>Blob</code>s read from the DA layer and send them to the
<code>Kernel</code>. The <code>Kernel</code> will return a list of deserialized <code>Batch</code>es of
transactions as well as the current <code>gas</code> price. (A "<code>Batch</code>" is a "<code>Blob</code>"
sent by a registered sequencer that has been succesfully deserialized into a
list of <code>Transaction</code>s)</li>
</ol>
<ul>
<li>Note that the list of <code>Batch</code>es returned by the <code>Kernel</code> does <em>not</em>
necessarily correspond exactly to the incoming <code>Blob</code>s. The <code>Kernel</code> might
decide to ignore some Blobs, or to store some in its internal state for
"deferred" execution. It might also add some <code>Batch</code>es saved from a previous
slot.</li>
</ul>
<ol start="2">
<li>
<p>Run the <code>begin_slot</code> hook, allowing modules to execute any initialization
logic</p>
</li>
<li>
<p>For each batch initialize the sequencer reward to zero and run the
<code>begin_batch</code> hook. Apply the transactions, rewarding or penalizing the
sequencer as appropriate. Finally, run the <code>end_batch</code> hook</p>
</li>
<li>
<p>Run the <code>end_slot</code> hook to allow modules to execute any final logic.</p>
</li>
<li>
<p>Compute the state change set and state root based on the transactions that
were executed.</p>
</li>
<li>
<p>Execute the <code>finalize</code> hook, which allows modules to compute any summary
information from the change set and make it available via RPC.</p>
</li>
</ol>
<p>For more details on the process of applying individual transactions, see the
<a href="./transaction-lifecycle.html">transaction lifecycle</a> document.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="sequencer-registration-via-forced-inclusion"><a class="header" href="#sequencer-registration-via-forced-inclusion">Sequencer Registration via Forced Inclusion</a></h1>
<p>Forced inclusion is a strategic mechanism in rollups designed to circumvent
sequencers that censor user transactions. It allows users to directly submit
transaction batches to the <a href="./da-layer.html">Data Availability Layer</a> instead of
going through a sequencer.</p>
<p>The Sovereign SDK supports this feature under specific conditions and
guidelines. Crucially, only "Register Sequencer" transactions are accepted for
forced inclusion; all other types will be ignored. For more details, see the
<a href="6-3-forced-sequencer-registration.html#rules">Rules</a> section.</p>
<h2 id="usage"><a class="header" href="#usage">Usage</a></h2>
<p>The Sovereign SDK limits the number of batches from unregistered sequencers
processed per rollup slot. This measure limits the use of this mechanism as a
denial-of-service (DOS) attack vector.</p>
<h3 id="process-for-forced-registration"><a class="header" href="#process-for-forced-registration">Process for Forced Registration</a></h3>
<ol>
<li>Create a batch containing a valid "Register Sequencer" transaction.</li>
<li>Submit the batch to the Data Availability layer.</li>
<li>Rollup nodes collect and execute the transaction.</li>
<li>If the transaction complies with all rules, the user is registered as a
sequencer and can submit regular transaction batches.</li>
</ol>
<h2 id="rules"><a class="header" href="#rules">Rules</a></h2>
<p>To ensure forced inclusion requests are processed correctly, the following rules
apply:</p>
<ul>
<li><strong>Transaction Limit</strong>: Only the first transaction in each batch is taken into
account. Any additional transactions will be discarded.</li>
<li><strong>Transaction Type</strong>: The transaction must be a "Register Sequencer"
transaction.</li>
<li><strong>Transaction Construction</strong>: The transaction must be properly formatted and
comply with standard transaction rules.</li>
<li><strong>Financial Requirements</strong>: Users must have enough funds to cover:
<ul>
<li>Pre-execution checks (including signature validation, deserialization and
transaction type checks).</li>
<li>Transaction execution costs.</li>
<li>A bond required for sequencer registration.</li>
</ul>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="gas-specification"><a class="header" href="#gas-specification">Gas Specification</a></h1>
<p>This document contains a detailed specification of the way gas is handled within
Sovereign's SDK. We use <code>&lt;., .&gt;</code> to denote the scalar product of two
multidimensional quantities.</p>
<h2 id="definition"><a class="header" href="#definition">Definition</a></h2>
<p>Gas is an ubiquitous concept in the blockchain space. It is a measure of the
computational effort required to perform an operation as part of a transaction
execution context. This is used to prevent the network from getting spammed by
regulating the use of computational resources by each participant in the
network.</p>
<h2 id="high-level-overview"><a class="header" href="#high-level-overview">High level overview</a></h2>
<p>We have drawn a lot of inspiration from the
<a href="https://ethereum.org/en/developers/docs/gas/">Ethereum gas model</a> in our gas
mechanism design. Given that Ethereum's gas is well understood and widely used
in the crypto industry, we believe that this will help users onboard more easily
while providing strong security guarantees out-of-the box. We have deliberately
chosen to tweak some concepts that were ill-suited to the rollups built using
Sovereing's SDK. In particular, sorted decreasing order of importance:</p>
<ul>
<li>We are using multidimensional gas units and prices.</li>
<li>We plan to using a dynamic gas target. Otherwise, the rollups built with
Sovereign's SDK follow the <a href="https://eips.ethereum.org/EIPS/eip-1559">EIP-1559</a>
specification by default.</li>
<li>Rollup transactions specify a <code>max_fee</code>, <code>max_priority_fee_bips</code>, and
<em>optional gas limit</em> <code>gas_limit</code>. The semantics of these quantities roughtly
match their definition in the
<a href="https://eips.ethereum.org/EIPS/eip-1559">EIP-1559 specification</a>.</li>
<li>Transaction rewards are decomposed into <code>base_fee</code> and <code>priority_fee</code>. The
<code>base_fee</code> <em>is only partially burnt by default</em>, the remaining amount is used
<em>to reward provers/attesters</em>. The <code>priority_fee</code> is used to reward the <em>block
sequencers</em>.</li>
<li>We are charging gas for every storage access within the module system by
default.</li>
<li>Customers of the SDK will have access to wrappers that allow to charge gas for
hash computation and signature checks.</li>
</ul>
<h2 id="a-design-for-multidimensional-gas"><a class="header" href="#a-design-for-multidimensional-gas">A design for multidimensional gas</a></h2>
<p>Sovereign SDK's rollups use multidimensional gas units and prices. For example,
this allows developers to take into account the differences between native and
zero-knowledge computational costs for the same operation. Indeed:</p>
<ul>
<li>Hashing is orders of magnitude more expensive when performed inside a
zero-knowledge circuit. The cost of proving the correct computation of two
different Hash may also vary much more than the cost of computing the hash
itself (<code>Poseidon</code> or <code>MiMc</code> vs <code>Sha2</code>).</li>
<li>Accessing a storage cell for the first time is much more expensive in <code>zk</code>
mode than in <code>native</code> mode. But <em>hot</em> storage accesses are practically free in
zero-knowledge.</li>
</ul>
<p>In the Sovereign SDK, we currently meter consumption in two dimensions - compute
and memory.</p>
<p>We have chosen to follow the
<a href="https://ethresear.ch/t/multidimensional-eip-1559/11651">multi-dimensional EIP-1559</a>
design for the gas pricing adjustment formulas. In essence:</p>
<ul>
<li>We are performing the gas price updates for each dimension separately. In
other words, each dimension follows a separate uni-dimensional EIP-1559 gas
price adjustment formula.</li>
<li>The gas price adjustment formula uses a <code>gas_target</code> reference, which is a
uni-dimensional gas unit that is compared to the gas consumed <code>gas_used</code>. The
<code>gas_price</code> is then adjusted to regulate the gas throughtput to get as close
as possible to the <code>gas_target</code>. We have the following invariant:
<code>0 &lt;= gas_used_slot &lt;= 2 * gas_target</code>.</li>
<li><em>Contrarily to Ethereum</em>, we are planning to design a dynamic <code>gas_target</code>.
The value of the <code>gas_target</code> will vary slowly to follow the evolution of the
rollup metrics we have described above. That way, Sovereign rollups can
account for major technological improvements in computation (such as zk-proof
generation throughtput), or storage cost.</li>
<li>Every transaction has to specify a scalar <code>max_fee</code> which is the maximum
amount of <em>gas tokens</em> that can be used to execute a given transaction.
Similarly, users have to specify a <code>max_priority_fee_per_gas</code> expressed in
basis points which can be used to reward the transaction sequencer.</li>
<li>The final sequencer reward is:
<code>seq_reward = min(max_fee - &lt;base_fee, gas_price&gt;, max_priority_fee_per_gas * &lt;base_fee, gas_price&gt;)</code>.</li>
<li>Users can provide an optional <code>gas_limit</code> field which is a maximum amount of
gas to be used for the transaction. This quantity is converted to a
uni-dimensional <code>remaining_funds</code> quantity by taking the scalar product with
the current <code>gas_price</code>.</li>
<li>If users provide the <code>gas_limit</code>, the rollup checks that
<code>&lt;gas_limit, current_gas_price&gt; &lt;= max_fee</code> (ie, the scalar product with the
current <code>gas_price</code>). If the check fails, the associated transaction is not
executed and the rollup raises a
<code>ReserveGasErrorReason::CurrentGasPriceTooHigh</code> error.</li>
</ul>
<h2 id="charging-gas-for-state-accesses"><a class="header" href="#charging-gas-for-state-accesses">Charging gas for state accesses.</a></h2>
<p>State accessors such as the <code>WorkingSet</code> or the <code>PreExecWorkingSet</code> charge some
gas whenever state is modified. If these accessors run out of gas, they return a
<code>StateAccessorError</code> and the execution gets reverted (or the sequencer is
penalized). Some state accessors - like <code>StateCheckpoint</code>, the <code>TxScratchpad</code> or
the <code>ApiStateAccessor</code> - don't charge for gas for state accesses. In that case,
the access methods return a <code>Result&lt;T, Infallible&gt;</code> type which can be unwrapped
safely using <code>unwrap_infallible</code>.</p>
<p>For now, we are enforcing simple cached access patterns - we are refunding some
gas if the value that is accessed/modified is <em>hot</em> (ie has been already
accessed and is cached).</p>
<h2 id="gas-rewards"><a class="header" href="#gas-rewards">Gas rewards.</a></h2>
<p>The gas consumed during transaction execution is used to reward both
provers/attesters and block sequencers. The <code>base_fee</code>, ie the total amount of
gas consumed by the transaction execution is partially burnt (the amount to burn
is specified by the <code>PERCENT_BASE_FEE_TO_BURN</code> constant), and the remaining
portion is locked in a reward pool to be redeemed by provers/attesters. The
<code>priority_fee</code> is also partially burnt and used to reward block sequencers.</p>
<h2 id="additional-data-structures-that-can-be-used-to-charge-gas"><a class="header" href="#additional-data-structures-that-can-be-used-to-charge-gas">Additional data structures that can be used to charge gas.</a></h2>
<p>We have a couple of additional data structures that can be used to charge gas.
These are:</p>
<ul>
<li><code>MeteredHasher</code>: a wrapper structure that can be used to charge gas for hash
computation.</li>
<li><code>MeteredSignature</code>: a wrapper structure that can be used to charge gas for
signature checks.</li>
<li><code>MeteredBorshDeserialize</code>: a supertrait that can be used to charge gas for
structures implementing <code>BorshDeserialize</code>.</li>
</ul>
<h2 id="structure-of-the-implementation"><a class="header" href="#structure-of-the-implementation">Structure of the implementation</a></h2>
<p>The core of the gas implementation is located within the <code>sov-modules-api</code> crate
in the following modules/files:</p>
<ul>
<li><code>module-system/sov-modules-api/src/common/gas.rs</code>: contains the implementation
of the <code>Gas</code> and <code>GasMeter</code> traits. These are the core interfaces that are
consumed by the API. The <code>Gas</code> trait defines the way users can interact with
multidimensional gas units. The <code>GasMeter</code> is the interface implemented by
every data structure that contains or consumes gas (such as the <code>WorkingSet</code>
which contains a <code>TxGasMeter</code>, or the <code>PreExecWorkingSet</code> that may contain a
<code>SequencerStakeMeter</code>).</li>
<li><code>module-system/sov-modules-api/src/common/hash.rs</code>: contains the
implementation of the <code>MeteredHasher</code> which is a wrapper structure that can be
used to charge gas for hash computation.</li>
<li><code>module-system/sov-modules-api/src/transaction.rs</code>: contains the
representation of the transaction type that is used within the SDK. These
structures contain the <code>max_fee</code>, <code>max_priority_fee_bips</code> and <code>gas_limit</code>
fields that represent the maximum amount of gas tokens to use for the
transaction, the maximum priority fee to pay the sequencer (in basis points),
and an optionnal multidimensional gas limit (ie the maximum amount of gas to
be consumed for this transaction).</li>
</ul>
<p>Outside of the <code>sov-modules-api</code>, within the module system:</p>
<ul>
<li><code>module-system/module-implementations/sov-chain-state/src/gas.rs</code>:
<code>compute_base_fee_per_gas</code> contains the implementation of the gas price update
which follows our modified version of the <code>EIP-1559</code>. The gas price is updated
within the <code>ChainState</code>'s module lifecycle hooks
(<code>ChainState::begin_slot_hook</code> updates the gas price,
<code>ChainState::end_slot_hook</code> updates the gas consumed by the transaction).</li>
<li><code>module-system/module-implementations/sov-sequencer-registry/src/capabilities.rs</code>:
contains the implementationn of the <code>SequencerStakeMeter</code> which is the data
structure used to meter the sequencer stake before the transaction's execution
starts.</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
